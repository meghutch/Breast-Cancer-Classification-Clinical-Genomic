{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Clinical Outcomes of Breast Cancer Patients.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghutch/Breast-Cancer-Classification-Clinical-Genomic/blob/master/Predicting_Clinical_Outcomes_of_Breast_Cancer_Patients_Trouble_shooting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ICfvGHiQnDI",
        "colab_type": "text"
      },
      "source": [
        "# **Predicting Clinical Outcomes of Breast Cancer Patients**\n",
        "\n",
        "**Author:** Meg Hutch\n",
        "\n",
        "**Date:** October 31, 2019\n",
        "\n",
        "**Objective:** Examining the data from Lee's ML course\n",
        "\n",
        "This project will investigate predicting the survival of patients diagnosed with breast cancer using\n",
        "the METABRIC (Molecular Taxonomy of Breast Cancer International Consortium) dataset [1, 2].\n",
        "METABRIC contains clinical and demographic data, DNA sequencing, copy-number, and gene\n",
        "expression data for over 2000 patients.\n",
        "\n",
        "**The first part of this analysis will examine whether low dimensional clinical data can be used to predict survivial (binary classification)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pG01kP6UVC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mamswLh8QkLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect Colab to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sds0C37hUMd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Data\n",
        "bc_data = pd.read_csv('/content/drive/My Drive/Projects/Breast_Cancer_Classification/Data/data_clinical_patient.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HKDUxUMVzhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bc_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAKBHKzCa4DH",
        "colab_type": "text"
      },
      "source": [
        "# **Pre-Process Data**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P42uFeTBlPX0",
        "colab_type": "text"
      },
      "source": [
        "Rows 0-3 contain definitions of data and data types. We can remove these"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_Od_3KdbGQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bc_data = bc_data.iloc[4:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prEZQHwscm0B",
        "colab_type": "text"
      },
      "source": [
        "Convert first row to header name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWaxqLvXbO1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert first row to header name\n",
        "bc_data = bc_data.rename(columns=bc_data.iloc[0]).drop(bc_data.index[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0yvqaoNcy3I",
        "colab_type": "text"
      },
      "source": [
        "Convert column names to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85VrahjfcP3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert column names to lowercase\n",
        "bc_data.columns = map(str.lower, bc_data.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xkv2nypc3pi",
        "colab_type": "text"
      },
      "source": [
        "# **Explore Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48AzbwtVeMId",
        "colab_type": "text"
      },
      "source": [
        "**Total Number of Patients**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJDYGATKc9Cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Total Number of Patients:', len(bc_data.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QhPQWmOmbOb",
        "colab_type": "text"
      },
      "source": [
        "**Remove any incomplete cases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KMNveVEmd4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bc_data = bc_data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVUYoG0em0yg",
        "colab_type": "text"
      },
      "source": [
        "**Re-Examine Total Number of Patients**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya3DtgqCm6Q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Total Number of Patients after Removing NAs:', len(bc_data.index)) # This removes about 1000 patients from the analysis "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WtlCLbDnZPE",
        "colab_type": "text"
      },
      "source": [
        "**In the project directions, it says we can treat \"Died of Other Causes\" as living. Thus, change the category title as such.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92-6YOPUnT4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bc_data['vital_status'] = bc_data['vital_status'].replace({'Living': 'Living', 'Died of Disease': 'Died of Disease', 'Died of Other Causes': 'Living'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qk2ZQEOoAV4",
        "colab_type": "text"
      },
      "source": [
        "**Examine Variable Names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH4dLopKoBwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bc_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cdw--Ybnz3G",
        "colab_type": "text"
      },
      "source": [
        "**Examine Variable Distributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VRllXFHnslSA",
        "colab": {}
      },
      "source": [
        "plt1 = bc_data.histological_subtype.value_counts().plot(kind=\"bar\")\n",
        "plt1.tick_params(axis=\"x\", labelsize=11, labelrotation= -45)\n",
        "plt1.set_title(\"Histological Subtype\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-o8WLbopslSI",
        "colab": {}
      },
      "source": [
        "plt2 = bc_data.vital_status.value_counts().plot(kind=\"bar\")\n",
        "plt2.tick_params(axis=\"x\", labelsize=11, labelrotation= -45)\n",
        "plt2.set_title(\"Survival\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K01kgzkAslSL",
        "colab": {}
      },
      "source": [
        "plt3 = bc_data.threegene.value_counts().plot(kind=\"bar\")\n",
        "plt3.tick_params(axis=\"x\", labelsize=11, labelrotation= -45)\n",
        "plt3.set_title(\"Three Gene Classifier\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "byp8nJ1eslSO",
        "colab": {}
      },
      "source": [
        "plt4 = bc_data.cellularity.value_counts().plot(kind=\"bar\")\n",
        "plt4.tick_params(axis=\"x\", labelsize=11, labelrotation= 360)\n",
        "plt4.set_title(\"Cellularity\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wlztHaj0slSS",
        "colab": {}
      },
      "source": [
        "plt5 = bc_data.chemotherapy.value_counts().plot(kind=\"bar\")\n",
        "plt5.tick_params(axis=\"x\", labelsize=11, labelrotation= 360)\n",
        "plt5.set_title(\"Chemotherapy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bj3TEWfLslST",
        "colab": {}
      },
      "source": [
        "# Convert object to float\n",
        "age = bc_data['age_at_diagnosis'].astype(float)\n",
        "\n",
        "# Define bins\n",
        "bin_edges = [0,10,20,30,40,50,60,70,80,90,100]\n",
        "\n",
        "plt.hist(age,\n",
        "         bins=bin_edges,\n",
        "         density=False,\n",
        "         histtype='bar',\n",
        "         color='b',\n",
        "         edgecolor='k',\n",
        "         alpha=0.5)\n",
        "\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number Patients')\n",
        "plt.title('Age at Diagnosis (years)')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uBVDpNQrslSW",
        "colab": {}
      },
      "source": [
        "# Convert object to float\n",
        "os = bc_data['os_months'].astype(float)\n",
        "\n",
        "# Define bins\n",
        "bin_edges = [25,50,75,100,125,150,175,200,225,250,275,300,325]\n",
        "\n",
        "plt.hist(os,\n",
        "         bin_edges,\n",
        "         density=False,\n",
        "         histtype='bar',\n",
        "         color='b',\n",
        "         edgecolor='k',\n",
        "         alpha=0.5)\n",
        "\n",
        "plt.xlabel('Months')\n",
        "plt.ylabel('Number Patients')\n",
        "plt.title('Overall Surivival (months)')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGGctvqHpZNA",
        "colab_type": "text"
      },
      "source": [
        "**Examine Patient Outcomes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghuzctC8pc2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt_out = bc_data.vital_status.value_counts().plot(kind=\"bar\")\n",
        "plt_out.tick_params(axis=\"x\", labelsize=11, labelrotation= -45)\n",
        "plt_out.set_title(\"Survival\")\n",
        "\n",
        "# Calculate Percents\n",
        "count_outcomes = bc_data.groupby(['vital_status']).size()\n",
        "print(count_outcomes)\n",
        "\n",
        "print('Percent Living: {:.1f}'.format(count_outcomes[\"Living\"]/len(bc_data.index)))\n",
        "print('Percent Died of Disease: {:.1f}'.format(count_outcomes[\"Died of Disease\"]/len(bc_data.index)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwuC2fW8pbpA",
        "colab_type": "text"
      },
      "source": [
        "# **Pre-Process Data**#\n",
        "\n",
        "Because some categorical features have multiple categories, we need to use one-hot-encoding to represent these varaibles in the dataset. Just creating numeric levels won't always make sense in the case of features like caludin_subtype which are genomic classifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q-GNCprraJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determine which variables we want to one-hot-encode\n",
        "print('Cellularity:', bc_data['cellularity'].unique())\n",
        "print('Chemotherapy:',bc_data['chemotherapy'].unique())\n",
        "print('Er_ihc:',bc_data['er_ihc'].unique())\n",
        "print('Her2_snp6:',bc_data['her2_snp6'].unique())\n",
        "print('Hormone Therapy:',bc_data['hormone_therapy'].unique())\n",
        "print('Inferred_menopausal_state:',bc_data['inferred_menopausal_state'].unique())\n",
        "print('Interclust:',bc_data['intclust'].unique())\n",
        "print('Claudin_Subtype:',bc_data['claudin_subtype'].unique())\n",
        "print('Threegene:',bc_data['threegene'].unique())\n",
        "print('Laterality:',bc_data['laterality'].unique())\n",
        "print('Radio_Therapy:',bc_data['radio_therapy'].unique())\n",
        "print('Histological_Subtype:',bc_data['histological_subtype'].unique())\n",
        "print('Breast_Surgery:',bc_data['breast_surgery'].unique())\n",
        "print('Vital_status:',bc_data['vital_status'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpXs0AL6rksb",
        "colab": {}
      },
      "source": [
        "# Convert patinet_ids to row names first\n",
        "bc_data = bc_data.set_index(bc_data.patient_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pJqbr_W0rsrN",
        "colab": {}
      },
      "source": [
        "# Create dataframe with the unchange varaibles - this will contain numeric variables\n",
        "bc_data1 = bc_data[['lymph_nodes_examined_positive', 'npi', 'age_at_diagnosis', 'os_months', 'vital_status']]\n",
        "\n",
        "# Seperate the dataframes into the varaibles that we will want to reshape - we can then recombine after - anything that has more than 2 levels\n",
        "\n",
        "# Cellularity\n",
        "cell_df = bc_data[['cellularity']]\n",
        "cell_df = pd.get_dummies(cell_df,prefix=['cellularity'])\n",
        "\n",
        "# Chemotherapy\n",
        "chemo_df = bc_data[['chemotherapy']]\n",
        "chemo_df = pd.get_dummies(chemo_df,prefix=['chemotherapy'])\n",
        "\n",
        "# Cohort\n",
        "cohort_df = bc_data[['cohort']]\n",
        "cohort_df = pd.get_dummies(cohort_df,prefix=['cohort'])\n",
        "\n",
        "# er_ihc\n",
        "er_df = bc_data[['er_ihc']]\n",
        "er_df = pd.get_dummies(er_df,prefix=['er_ihc'])\n",
        "\n",
        "# Her2_snp6\n",
        "her2_df = bc_data[['her2_snp6']]\n",
        "her2_df = pd.get_dummies(her2_df,prefix=['her2'])\n",
        "\n",
        "# Hormone Therapy\n",
        "ht_df = bc_data[['hormone_therapy']]\n",
        "ht_df = pd.get_dummies(ht_df,prefix=['hormone_therapy'])\n",
        "\n",
        "# Inferred Menopasual State\n",
        "ims_df = bc_data[['inferred_menopausal_state']]\n",
        "ims_df = pd.get_dummies(ims_df,prefix=['ims_df'])\n",
        "\n",
        "# Interclust\n",
        "intclust_df = bc_data[['intclust']]\n",
        "intclust_df = pd.get_dummies(intclust_df,prefix=['intclust'])\n",
        "\n",
        "# Claduin Subtype\n",
        "cs_df = bc_data[['claudin_subtype']]\n",
        "cs_df = pd.get_dummies(cs_df,prefix=['claudin_subtype'])\n",
        "\n",
        "# Threegene\n",
        "three_df = bc_data[['threegene']]\n",
        "three_df = pd.get_dummies(three_df,prefix=['threegene'])\n",
        "\n",
        "# Laterality\n",
        "lat_df = bc_data[['laterality']]\n",
        "lat_df = pd.get_dummies(lat_df,prefix=['laterality'])\n",
        "\n",
        "# Radiotherapy\n",
        "rt_df = bc_data[['radio_therapy']]\n",
        "rt_df = pd.get_dummies(rt_df,prefix=['radio_therapy'])\n",
        "\n",
        "# Histological_Subtype\n",
        "hist_df = bc_data[['histological_subtype']]\n",
        "hist_df = pd.get_dummies(hist_df,prefix=['hist'])\n",
        "\n",
        "# Breast Surgery\n",
        "surg_df = bc_data[['breast_surgery']]\n",
        "surg_df = pd.get_dummies(surg_df,prefix=['breast_surgery'])\n",
        "\n",
        "# Combine dataframes\n",
        "bc_data2 = cell_df.reset_index(drop=True).merge(her2_df.reset_index(drop=True), left_index=True, right_index=True)\n",
        "bc_data2 = bc_data2.reset_index(drop=True).merge(intclust_df.reset_index(drop=True), left_index=True, right_index=True)\n",
        "bc_data2 = bc_data2.reset_index(drop=True).merge(cs_df.reset_index(drop=True), left_index=True, right_index=True)\n",
        "bc_data2 = bc_data2.reset_index(drop=True).merge(three_df.reset_index(drop=True), left_index=True, right_index=True)\n",
        "bc_data2 = bc_data2.reset_index(drop=True).merge(hist_df.reset_index(drop=True), left_index=True, right_index=True)\n",
        "\n",
        "# Merge all data \n",
        "bc_data = bc_data2.reset_index(drop=True).merge(bc_data1.reset_index(drop=True), left_index=True, right_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqRtZ1qprmfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bc_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_E_xiDqgsQuv"
      },
      "source": [
        "Create dummy variables for Vital Status - Our Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x0QlhIhysQuy",
        "colab": {}
      },
      "source": [
        "bc_data['vital_status'] = bc_data.vital_status.map({'Living':0, 'Died of Disease':1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yNDj16JSsW56"
      },
      "source": [
        "Covert numeric varaibles as such, right now they are all non-null objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m7wveepYsW5_",
        "colab": {}
      },
      "source": [
        "bc_data = bc_data.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhi38nXMsW6D",
        "colab": {}
      },
      "source": [
        "bc_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvE2so2quSLS",
        "colab_type": "text"
      },
      "source": [
        "# **Predicting Clinical Outcomes**\n",
        "\n",
        "We will attempt to predict vital status using:\n",
        "\n",
        "* Logistic Regression\n",
        "* Random Forest\n",
        "* Neural Networks. \n",
        "\n",
        "Logistic regression and random forst classiers can help serve as a benchmark of performance once we develop our neural network classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKzlNG-xu4EN",
        "colab_type": "text"
      },
      "source": [
        "# **Training and Testing Split**\n",
        "\n",
        "For all of our classification methods, we will create a training and a testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxdYyZxEujxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Packagess\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKwf3jzovYN0",
        "colab_type": "text"
      },
      "source": [
        "Format the bc_data into a features and label dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H421ISlCvf4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let x represent the input features; y the labels\n",
        "\n",
        "# Want to remove os_months, os_status, and vital_status from inputs since these are what we are trying to predict. We will include vital status as our label. I already remove os_status by leaving it out of pre-processing above, since I felt this was similar to vital_status\n",
        "\n",
        "# create x to represent the input features; y is the label; \n",
        "x =  bc_data.drop(['os_months', 'vital_status'], axis=1)\n",
        "y = bc_data.vital_status"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jot8CaTpvfEP",
        "colab_type": "text"
      },
      "source": [
        "Split the data into testing and training sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuPWs5pQv5d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7UGiy4twHbY",
        "colab_type": "text"
      },
      "source": [
        "View the shapes of the training and testing sets; the datasets ending in \"train\" are our training sets; similarly, those ending in \"test\" are the testing; x prefix always represents the input features, y the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujubXxyzwU14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assess the trainig and testing sets previously created\n",
        "print('Training Features Shape:', X_train.shape)\n",
        "print('Training Labels Shape:', y_train.shape)\n",
        "print('Testing Features Shape:', X_test.shape)\n",
        "print('Testing Labels Shape:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2u1NBiEwYeS",
        "colab_type": "text"
      },
      "source": [
        "Examine the class distributions - these are similar splits between the training and testing sets. This is also representative of the number of cases throughout the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzAqXr4pwX3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Malignant = 1; Count the number of malignant and determine the percentage (traning has 426 values, testing has 143)\n",
        "print('Died of Diseases in Training Set:', np.count_nonzero(y_train == 1))\n",
        "print('Died of Diseases in Testing Set:', np.count_nonzero(y_test == 1))\n",
        "\n",
        "# Percents\n",
        "print('% Died of Diseases Cases in Training Set:', round(np.count_nonzero(y_train == 1)/1139*100,2))\n",
        "print('% Died of Diseases Cases in Testing Set:', round(np.count_nonzero(y_test == 1)/380*100,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaHX5zydw3H2",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic Regression**\n",
        "\n",
        "These steps were followed from the following tutorial:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BdqKQJ2x0em",
        "colab_type": "text"
      },
      "source": [
        "**Define and Run the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u4X6MFSxzox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the model (using default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-lsca1IyC-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRDRV7DIyGL5",
        "colab_type": "text"
      },
      "source": [
        "**Model Evaluation Using Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyJQT7fHyLeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the metrics class\n",
        "from sklearn import metrics\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CRpg41RySQT",
        "colab_type": "text"
      },
      "source": [
        "The confusion matrix generated above is in the form of an array. Diagnosal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. The diagonal starting with the top left to the bottom right hand corner are actual predidictions, while the bottom left corner to the top right corner are incorrect predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2BvUFrAy04x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred),3))\n",
        "print(\"Precision:\",round(metrics.precision_score(y_test, y_pred),3))\n",
        "print(\"Recall:\",round(metrics.recall_score(y_test, y_pred),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAZw8J4mzxsD",
        "colab_type": "text"
      },
      "source": [
        "**ROC**\n",
        "\n",
        "The Reciever Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y11_Tmpu39qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label = \"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "print('AUC:', round(auc,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M5jCMHP8COG",
        "colab_type": "text"
      },
      "source": [
        "# **Random Forest Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GIPkb3jy0Hn",
        "colab_type": "text"
      },
      "source": [
        "I followed the tutorial here:  https://towardsdatascience.com/random-forest-in-python-24d0893d51c0 and https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpN91JbL9JOA",
        "colab_type": "text"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dsBsgBv9LWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FENSsY5l9aDT",
        "colab_type": "text"
      },
      "source": [
        "**Make Predictions on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yKF_xdj9dbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_test)\n",
        "# Probabilities for each class\n",
        "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - y_test)\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5pOirYXDrEn",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating the Performance**\n",
        "\n",
        "For Classification Problems the metrics used to evaluate an algorithm are accuracy, confusion matrix, precision, recall, and F1 values.\n",
        "\n",
        "We can also perform cross-fold validation to have a better understanding of the results\n",
        "\n",
        "Reference: #https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu4eohUxFVaA",
        "colab_type": "text"
      },
      "source": [
        "**ROC on the Full Data**\n",
        "\n",
        "\n",
        "We make class predictions (predict) as well as predicted probabilities (predict_proba) to calculate the ROC AUC. Once we have the testing predictions, we can calculate the ROC AUC. https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19CamuL7EZzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrO0-IuE-o0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Calculate ROC AUC\n",
        "roc_value = roc_auc_score(y_test, rf_probs) \n",
        "\n",
        "roc_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyKejE-yF88f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Probabilities for each class\n",
        "# Note from scikit learn: re fpr and tpr: \"Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both fpr and tpr, which are sorted in reversed order during their calculation.\"\n",
        "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, rf_probs)\n",
        "auc = metrics.roc_auc_score(y_test, rf_probs)\n",
        "auc = round(auc, 4)\n",
        "plt.plot(fpr, tpr, label=\"date 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U0IYU-uFzGZ",
        "colab_type": "text"
      },
      "source": [
        "**10 Cross-Fold Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQRXv1rIE9UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc_cv_score = cross_val_score(rf, x, y, cv=10, scoring='roc_auc') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEonYh2WEhkU",
        "colab_type": "text"
      },
      "source": [
        "Below, we also can examine the confusion matrix, the classification report containing precision, recall, f1-score, and support, All AUC scores, and the mean AUC score\n",
        "\n",
        "The **confusion matrix** is useful for giving false positives and false negatives\n",
        "\n",
        "The **ROC Curve** plots out the true positive rate vs the false positive rate at various thresholds\n",
        "\n",
        "The **ROC AUC Scoring** used in the cross-validation model shows the area under the ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haZRHJqGcv9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
        "print('\\n')\n",
        "print(\"=== Accuracy Score ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3zb1pR3vz0V",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic Regression and Random Forest Results**\n",
        "\n",
        "**Logistic Regression classifier:**\n",
        "\n",
        "* AUC: 0.667\n",
        "* Accuracy: 0.716\n",
        "* Precision: 0.532\n",
        "* Recall: 0.295\n",
        "\n",
        "\n",
        "**Random Forest classifier:**\n",
        "\n",
        "* AUC: 0.62\n",
        "* AUC Mean 10 Fold Validation: 0.64\n",
        "* Accuracy 10 Fold Validation: 0.689"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "420bkLBwGp6A",
        "colab_type": "text"
      },
      "source": [
        "# **PyTorch Neural Network For Classification**\n",
        "\n",
        "We will evaluate the use of a neural network classifier on the testing data as developed above and compare the outputs to the logistic regression and random forest classifiers above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhs-KCueHlKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import PyTorch packages\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch import optim\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WMA1F7XxV8a",
        "colab_type": "text"
      },
      "source": [
        "**Format the Training Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7pj4XyVzUIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert data into arrays\n",
        "xb = np.array(X_train, dtype = \"float32\")\n",
        "yb = np.array(y_train, dtype = \"float32\")\n",
        "\n",
        "# Convert arrays into tensors\n",
        "xb = torch.from_numpy(xb)\n",
        "yb = torch.from_numpy(yb)\n",
        "\n",
        "# Combine the arrays\n",
        "trainloader = TensorDataset(xb, yb)\n",
        "\n",
        "# Define the batchsize\n",
        "batch_size = 25\n",
        "\n",
        "# Training Loader\n",
        "trainloader = DataLoader(trainloader, batch_size, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtV6u9fUzrxx",
        "colab_type": "text"
      },
      "source": [
        "**Format the Testing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xoH_jHfzwc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert data into arrays\n",
        "xb = np.array(X_test, dtype = \"float32\")\n",
        "yb = np.array(y_test, dtype = \"float32\")\n",
        "\n",
        "# Convert arrays into tensors\n",
        "xb = torch.from_numpy(xb)\n",
        "yb = torch.from_numpy(yb)\n",
        "\n",
        "# Combine the arrays\n",
        "testloader = TensorDataset(xb, yb) \n",
        "\n",
        "# Define the batchsize\n",
        "batch_size= 25\n",
        "\n",
        "# Training Loader\n",
        "testloader = DataLoader(testloader, batch_size, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOzyQUmc0PJ6",
        "colab_type": "text"
      },
      "source": [
        "**Create Neural Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2XAPEny0Thm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model with hidden layers - 39 inputs\n",
        "model = nn.Sequential(nn.Linear(39, 17),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(17, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Set optimizer and learning rate\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "# Could also use Adam optimizer; similar to stochastic gradient descent, but uses momentum which can speed up the actual fitting process, and it also adjusts the learning rate for each of the individual parameters in the model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Set 100 epochs to start\n",
        "epochs = 100\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for xb, yb in trainloader:\n",
        "\n",
        "        # Flatten yb --- or should this be xb?\n",
        "        #yb = yb.view(yb.shape[0], -1)\n",
        "        \n",
        "        # Clear the gradients, do this because gradients are accumulated\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Training pass\n",
        "        output = model.forward(xb)\n",
        "        loss = criterion(output, yb.long()) # Loss calculated from the output compared to the labels \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item() # loss.item() gets the scalar value held in the loss. Running_loss = 0, \n",
        "        # += notation, says \"Add a value and the variable and assigns the result to that variable.\" So, adds the running_loss (0) with loss.item and assigns to running_loss\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9gy_VJT4Za5",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REsEMyoM2gxf",
        "colab_type": "text"
      },
      "source": [
        "The goal of validation is to measure the model's performance on data that isn't part of the training set. Performance here is up to the developer to define though. Typically, this is just accuracy, the percentage of classes the network predicted correctly. \n",
        "\n",
        "First, do a forward pass with one batch from the test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UexgheavO9L9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = next(iter(testloader))\n",
        "\n",
        "# Get the class probabilities \n",
        "ps = torch.exp(model(xb))\n",
        "\n",
        "# Make sure the shape is appropriate\n",
        "print(ps.shape)\n",
        "print(ps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE5WEs4y2qWU",
        "colab_type": "text"
      },
      "source": [
        "With the probabilities, we can get the most likely class using the ps.topk method. This returns the k highest values. Since we just want the most likely class, we can use ps.topk(1). This returns a tuple of the top-k values and the top-k indices. If the highest value is the first element, we'll get back 4 as the index. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqBllpwH2n-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_p, top_class = ps.topk(1, dim=1)\n",
        "# Look at the most likely classes \n",
        "print(top_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BISWMWOw2uXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GmKrdfn2veS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ps[:25] #we can see how to correpsonding probabilities were classified above"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq4s-_gX2v0u",
        "colab_type": "text"
      },
      "source": [
        "Now we can check if the predicted classes match the labels. This is simple to do by equating top_class and labels, but we have to be careful of the shapes. To get the equality to work out the way we want, top_class and the labels (yb) must have the same shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE9f0bhM2y9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "equals = top_class == yb.view(*top_class.shape) \n",
        "print(equals)\n",
        "print(yb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiWb1-fv21Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_class = top_class.view(*yb.shape) \n",
        "top_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWD1FSPT23Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cast top_class to float32\n",
        "top_class = top_class.to(dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7GS83Kb25_Y",
        "colab_type": "text"
      },
      "source": [
        "Now we need to calculate the correct predictions. \n",
        "\n",
        "equals has binary values, either 0 or 1. This means that if we just sum up all the values and divide by the total number of values, we get the percentage of correct predictions. This is the same operation as taking the mean, so we can get the accuracy with a call to torch.mean. \n",
        "\n",
        "So we'll need to convert equals to a float tensor. Note that when we take torch.mean it returns a scalar tensor, to get the actual value as a float we'll need to do accuracy.item()\n",
        "\n",
        "**Edit: Can use accuracy metric below!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Eduw8C-29M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
        "#print(f'Accuracy: {accuracy.item()*100}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3HHE4nX4DFL",
        "colab_type": "text"
      },
      "source": [
        "**Confusion Matrix**\n",
        "\n",
        "The confusion matrix is conducted on the test batch created above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLWZQtDJ3z-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating True Positive Rate (Sensitivity) and False Positive Rate (Sensitivity)\n",
        "# https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
        "\n",
        "CM = confusion_matrix(yb, top_class)\n",
        "\n",
        "TN = CM[0][0] # True Negative is high - is this because our model has greater sensitivty\n",
        "FN = CM[1][0] # False Negative\n",
        "TP = CM[1][1] # True Positive\n",
        "FP = CM[0][1] # False POsitive \n",
        "\n",
        "CM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0J1jHJq3O1W",
        "colab_type": "text"
      },
      "source": [
        "**Plot ROC of the Model**\n",
        "\n",
        "**ROC Reference:** https://machinelearningmastery.com/how-to-score-probability-predictions-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r3J_w2_3dzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "top_p = top_p.detach().numpy()\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(yb, top_p, pos_label=1)\n",
        "\n",
        "# Compute ROC area\n",
        "roc_auc = round(auc(fpr, tpr),3)\n",
        "print('ROC area is {0}'.format(roc_auc))\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlim([-0.01, 1.0])\n",
        "plt.ylim([0.0, 1.01])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD_skybNUruR",
        "colab_type": "text"
      },
      "source": [
        "**Confusion Matrix, Classification Report: Precission, Recall, F1, Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yYA8mtmUd3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(yb, top_class))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(yb, top_class))\n",
        "print('\\n')\n",
        "print(\"=== Accuracy Score ===\")\n",
        "print(\"Accuracy:\", accuracy_score(yb, top_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fxJVhVFnOQ",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Network Results**\n",
        "\n",
        "1) 1 Hidden Layer with 17 neurons, optimizer: SGD, lr = 0.001, epochs = 100\n",
        "\n",
        "* AUC from ROC plot: 0.676\n",
        "* Accuracy: 56%\n",
        "\n",
        "2) 1 Hidden Layer with 17 neurons, optimizer: SGD, lr = 0.003, epochs = 100\n",
        "\n",
        "* AUC from ROC plot: 0.691\n",
        "* Accuracy: 56%\n",
        "\n",
        "3) 1 Hidden Layer with 17 neurons, optimizer: Adam, lr = 0.001, epochs = 100\n",
        "\n",
        "* AUC from ROC plot: 0.765\n",
        "* Accuracy: 60%\n",
        "\n",
        "**3) 1 Hidden Layer with 17 neurons, optimizer: Adam, lr = 0.003, epochs = 100**\n",
        "\n",
        "* **AUC from ROC plot: 0.794**\n",
        "* **Accuracy: 64%**\n",
        "\n",
        "4) 1 Hidden Layer with 17 neurons, optimizer: Adam, lr = 0.004, epochs = 100\n",
        "\n",
        "* AUC from ROC plot: 0.794\n",
        "* Accuracy: 60%\n",
        "\n",
        "5) 1 Hidden Layer with 17 neurons, optimizer: Adam, lr = 0.002, epochs = 100\n",
        "\n",
        "* AUC from ROC plot: 0.756\n",
        "* Accuracy: 56%\n",
        "\n",
        "6) 2 Hidden Layer with 17, 8 neurons, optimizer: Adam, lr = 0.003, epochs = 100\n",
        "\n",
        "* AUC from ROC plot: 0.669\n",
        "* Accuracy: 56%\n",
        "\n",
        "7) 3 Hidden Layer with 17, 8 neurons, optimizer: Adam, lr = 0.001, epochs = 100\n",
        "\n",
        "* AUC from ROC plot: 0.765\n",
        "* Accuracy: 60%\n",
        "\n",
        "8) 3 Hidden Layer with 17, 8, 4 neurons, optimizer: Adam, lr = 0.001, epochs = 100\n",
        "\n",
        "* AUC from ROC plot: 0.787\n",
        "* Accuracy: 60%\n",
        "\n",
        "9) 3 Hidden Layer with 17, 10, 4 neurons, optimizer: Adam, lr = 0.001, epochs = 100\n",
        "\n",
        "* AUC from ROC plot:\n",
        "* Accuracy: \n",
        "\n",
        "**Batch Size 32**\n",
        "\n",
        "**10) 3 Hidden Layer with 17, 8 neurons, optimizer: Adam, lr = 0.001, epochs = 100**\n",
        "\n",
        "* AUC from ROC plot: 0.70\n",
        "* Accuracy: 0.6875 \n",
        "\n",
        "=== Classification Report ===\n",
        "   \n",
        "                precision    recall  f1-score   support\n",
        "         0.0       0.74      0.87      0.80        23\n",
        "         1.0       0.40      0.22      0.29         9\n",
        "\n",
        "    accuracy                           0.69        32\n",
        "    macro avg       0.57     0.55      0.54        32\n",
        "    weighted avg    0.64     0.69      0.66        32\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWgs7sYacTv_",
        "colab_type": "text"
      },
      "source": [
        "# **Updates/Next Steps:**\n",
        "\n",
        "**11.11.2019: Implemented the Neural Network models into the code and ran a few tests. Realized that I need to ensure that I am understanding the role of batch size. I also want to make sure I understand the following metrics: Accuracy, precision, recall, F1, AUC etc. I had run into problems with the AUC calucating, getting different results when I used top_p (probabilities) or top_class (binary predictions). From my reading, I am pretty sure we should be using probabilities in this calculation, which is good because it gives us much better results.**\n",
        "\n",
        "**I will continue raeding up on the aforementioned metrics and review the code in regards to AUC. Potentially will experiement with Batch Size as well.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOXFql40e6wR",
        "colab_type": "text"
      },
      "source": [
        "# **Experiements - Batch Size**\n",
        "\n",
        "**November 12, 2019:**\n",
        "\n",
        "1) **1 Hidden Layer with 17 neurons, optimizer: Adam, lr = 0.003, epochs = 100*, Batch size = 25**\n",
        "\n",
        "*Re-running the same test from above, but will copy and paste the Classification Report!*\n",
        "\n",
        "* **AUC from ROC plot:**\n",
        "* **Accuracy:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yc53y4ufhko",
        "colab_type": "text"
      },
      "source": [
        "**Refine the Model**\n",
        "\n",
        "I will copy the Udacity Inference Tutorial that computes accuracies, probabilities, ect in the the code when running the model. This will hopefully allow us to compute/examine results in less steps! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fe8jNhbfGy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model with hidden layers - 39 inputs\n",
        "model = nn.Sequential(nn.Linear(39, 17),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(17, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Set optimizer and learning rate\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "# Could also use Adam optimizer; similar to stochastic gradient descent, but uses momentum which can speed up the actual fitting process, and it also adjusts the learning rate for each of the individual parameters in the model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Set 100 epochs to start\n",
        "epochs = 100\n",
        "#steps = 0 - not sure what/if needed\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for xb, yb in trainloader:\n",
        "\n",
        "        # Flatten xb\n",
        "        xb = xb.view(xb.shape[0], -1)\n",
        "        \n",
        "        # Clear the gradients, do this because gradients are accumulated\n",
        "        optimizer.zero_grad()\n",
        "      \n",
        "        # Training pass\n",
        "        output = model.forward(xb)\n",
        "        loss = criterion(output, yb.long()) # Loss calculated from the output compared to the labels \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "          \n",
        "        running_loss += loss.item() # loss.item() gets the scalar value held in the loss. Running_loss = 0, \n",
        "        # += notation, says \"Add a value and the variable and assigns the result to that variable.\" So, adds the running_loss (0) with loss.item and assigns to running_loss\n",
        "   \n",
        "   # The else indicates to run the below code after the for loop completes \n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        # Turn off gradients for validation, saves memory and computation\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in testloader:\n",
        "                xb, yb = next(iter(testloader))  # I'm not sure we want this - results are better with it - just need to make sure this is appropriate - if I don't use this function the confusion matrix is always just a subset of the batch\n",
        "                ps = model(xb)\n",
        "                test_loss += criterion(ps, yb.long())\n",
        "\n",
        "                ps = torch.exp(ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == yb.view(*top_class.shape)\n",
        "                top_class = top_class.to(dtype=torch.float32) # Cast top_class to float32\n",
        "\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        test_losses.append(test_loss/len(testloader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "             \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "             \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "             \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATuUNrKojdn1",
        "colab_type": "text"
      },
      "source": [
        "**Analyze Training and Validation Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaPEchbxjBQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwW4apgyjH2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_losses, label = 'Training Loss')\n",
        "plt.plot(test_losses, label = \"Validaiton Loss\")\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLIEQ2ZUjllN",
        "colab_type": "text"
      },
      "source": [
        "**Examine Other Model Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "meAOJD93jvIu"
      },
      "source": [
        "**Confusion Matrix**\n",
        "\n",
        "The confusion matrix is conducted on the test batch created above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fNsyqRoNjvIx",
        "colab": {}
      },
      "source": [
        "# Calculating True Positive Rate (Sensitivity) and False Positive Rate (Sensitivity)\n",
        "# https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
        "\n",
        "CM = confusion_matrix(yb, top_class)\n",
        "\n",
        "TN = CM[0][0] # True Negative is high - is this because our model has greater sensitivty\n",
        "FN = CM[1][0] # False Negative\n",
        "TP = CM[1][1] # True Positive\n",
        "FP = CM[0][1] # False POsitive \n",
        "\n",
        "CM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViF372j5wnCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AuQY2_dpjvI2"
      },
      "source": [
        "**Plot ROC of the Model**\n",
        "\n",
        "**ROC Reference:** https://machinelearningmastery.com/how-to-score-probability-predictions-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3LemrA1LjvI3",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "#top_p = top_p.detach().numpy() # this doesn't seem to matter!\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(yb, top_p, pos_label=1)\n",
        "\n",
        "# Compute ROC area\n",
        "roc_auc = round(auc(fpr, tpr),3)\n",
        "print('ROC area is {0}'.format(roc_auc))\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlim([-0.01, 1.0])\n",
        "plt.ylim([0.0, 1.01])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSZxLAzajvI5"
      },
      "source": [
        "**Confusion Matrix, Classification Report: Precission, Recall, F1, Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SWwdtYZFjvI6",
        "colab": {}
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(yb, top_class))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(yb, top_class))\n",
        "print('\\n')\n",
        "print(\"=== Accuracy Score ===\")\n",
        "print(\"Accuracy:\", accuracy_score(yb, top_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKHR0e66mfYI",
        "colab_type": "text"
      },
      "source": [
        "We get vastly different results if I have the test set run/calculate? during the training. The AUC is very low, but I wonder if this is because the AUC in the prior models was being calculated on the samll batch 25 samples, whereas this might be with 100 epochs? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUqt5bIPOf3W",
        "colab_type": "text"
      },
      "source": [
        "I'm having vastly different results with the new model. I am going to try building the model a different way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7oa8zsoTscN",
        "colab_type": "text"
      },
      "source": [
        "**Other consideration:**\n",
        "\n",
        "*Should it be log_softmax or just softmax?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uICu1JE8aQlN",
        "colab_type": "text"
      },
      "source": [
        "# **Troubleshooting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exa4P7pqkw6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                ps = model(xb)\n",
        "                test_loss += criterion(ps, yb.long())\n",
        "\n",
        "                ps = torch.exp(ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == yb.view(*top_class.shape)\n",
        "                top_class = top_class.to(dtype=torch.float32) # Cast top_class to float32\n",
        "\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyRqe8gehHPM",
        "colab_type": "text"
      },
      "source": [
        "https://discuss.pytorch.org/t/how-to-apply-the-pretrained-model-on-testing-data-and-get-predictions-for-each-instance/10197/9\n",
        "\n",
        "The above may be helpful to refereence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFF5P0r7o6uH",
        "colab_type": "text"
      },
      "source": [
        "update: need to understand dataloader and iter() function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNQS5qQdpCzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The below function perhaps seemed to work \n",
        "# https://stackoverflow.com/questions/53280967/pytorch-nextitertraining-loader-extremely-slow-simple-data-cant-num-worke\n",
        "xb, yb = next(iter(testloader))\n",
        "\n",
        "batches = 10\n",
        "\n",
        "test_iter = iter(testloader)\n",
        "\n",
        "for i in range(batches):\n",
        "  xc, yb = next(test_iter)\n",
        "\n",
        "# Get the class probabilities \n",
        "ps = torch.exp(model(xb))\n",
        "ps2 = torch.exp(model(xc))\n",
        "\n",
        "# Make sure the shape is appropriate\n",
        "print(ps.shape)\n",
        "print(ps)\n",
        "print(ps2)\n",
        "ps == ps2\n",
        "\n",
        "## Perhaps this worked! "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Q6FwjdqY0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_iter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fehNMBgTqkCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://discuss.pytorch.org/t/iterating-through-a-dataloader-object/25437\n",
        "\n",
        "# New test\n",
        "it = iter(testloader)\n",
        "first_xb, first_yb = next(it)\n",
        "second_xb, second_yb = next(it)\n",
        "\n",
        "# Get the class probabilities \n",
        "ps = torch.exp(model(first_xb))\n",
        "ps2 = torch.exp(model(second_xb))\n",
        "\n",
        "# Make sure the shape is appropriate\n",
        "print(ps.shape)\n",
        "print(ps)\n",
        "print(ps2)\n",
        "ps == ps2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYqQHA-7rvbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test 3 - These are equal - so the next(iter(testloader)) just returns the same dataset - but this does not seem to be the case if shuffle = true back at the intitial dataloader intialization! \n",
        "\n",
        "xa, ya = next(iter(testloader))\n",
        "xd, yd = next(iter(testloader))\n",
        "\n",
        "print(ya)\n",
        "print(yd)\n",
        "\n",
        "ps = torch.exp(model(xa))\n",
        "ps2 = torch.exp(model(xd))\n",
        "\n",
        "ps == ps2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-HVtznwb05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iter test\n",
        "mytuple = (\"apple\", \"banana\", \"cherry\")\n",
        "myit = iter(mytuple)\n",
        "\n",
        "print(next(myit))\n",
        "print(next(myit))\n",
        "print(next(myit))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "536QV828pOJI",
        "colab_type": "text"
      },
      "source": [
        "**November 12, 2019 Updates:**\n",
        "\n",
        "This was a major troubleshooting day. I tried to implement the model used by Udacity Inference tutorial, but this severaly lowered the AUC, which makes me think I'm doing something wrong. \n",
        "\n",
        "The above reference showing the importance of iterating for each epoc seemed to perhaps work. I wonder too if this function in the main neural network is imperative/the same as the example directly above\n",
        "\n",
        "xb, yb = next(iter(testloader))\n",
        "\n",
        "I think it would also help for me to undestand in more depth how the AUC is calculated from the testing data. I think the first models I ran on Nov.11, I was potentially testing AUC on only 1 batch, and maybe even the same batch since the dataloader wasn't set to Shuffle. Maybe this explains the consistent performance metrics?? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBCgS8ddrM7W",
        "colab_type": "text"
      },
      "source": [
        "**Next Step: November 12, 2019:**\n",
        "\n",
        "Read the references re: dataloaders and iterators\n",
        "\n",
        "* https://discuss.pytorch.org/t/iterating-through-a-dataloader-object/25437/3\n",
        "\n",
        "* https://stackoverflow.com/questions/53280967/pytorch-nextitertraining-loader-extremely-slow-simple-data-cant-num-worke\n",
        "\n",
        "I also set shuffle = True in the dataloader intitialization step. I need to ensure that this is correct to do. \n",
        "\n",
        "According to the pytorch manual, https://pytorch.org/docs/stable/data.html, shuffle set to True - has the data reshuffled at every epoch. \n",
        "\n",
        "Once I troubleshoot, I'll revise and clean up the code and the commense with the experiements, hopefully with batchsize, there's a chance my code is fine, but I need to determine what the relationshiop between the testing set and AUC is with the way my code is currently structured.  \n",
        "\n",
        "**Tomorrow, I should also test the original model with dataloder set to shuffle!** "
      ]
    }
  ]
}
