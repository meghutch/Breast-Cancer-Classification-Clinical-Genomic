{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gene Expression Analysis - PCA_TroubleShooting",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghutch/Breast-Cancer-Classification-Clinical-Genomic/blob/master/PCA_TroubleShooting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdupOdmkztDr",
        "colab_type": "text"
      },
      "source": [
        "# **Predicting Clinical Outcomes of Breast Cancer Patients - Gene Expression Data**\n",
        "\n",
        "## **Principal Component Analysis**\n",
        "\n",
        "**Author:** Meg Hutch\n",
        "\n",
        "**Date:** November 15, 2019\n",
        "\n",
        "**Objective:** Apply Principal Component Analysis to Determine Which Genes to Include into our Neural Network \n",
        "\n",
        "**This specific version troubleshoots some discrepancies I found while reasearching these methods!**\n",
        "\n",
        "****Update: I did some testing and these methods don't seem to be causing significant differences. I will probably just need to later validate whether the PC change using the different methods, but for now, I think I can go ahead, clean up the code****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwGGM9lLGfZM",
        "colab_type": "text"
      },
      "source": [
        "**References**\n",
        "\n",
        "* https://www.youtube.com/watch?v=Lsue2gEM9D0&list=PLblh5JKOoLUIcdlgu78MnlATeyx4cEVeR&index=54&t=0s\n",
        "\n",
        "* https://www.youtube.com/watch?v=FgakZw6K1QQ\n",
        "\n",
        "* https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60 (**concerned that perhaps error in the code regarding the fit_transform function**)\n",
        "\n",
        "* https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python \n",
        "\n",
        "* https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5qG3lqmAruE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpR6ASOpzsOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect Colab to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ltCT9Zv8LAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Data\n",
        "gene_data = pd.read_csv('/content/drive/My Drive/Projects/Breast_Cancer_Classification/Data/merged_expression.txt', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57X200aH-HFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gene_data.head()\n",
        "#genes.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chNv2A3jUNQr",
        "colab_type": "text"
      },
      "source": [
        "# **Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_29Kdk_59QqC",
        "colab_type": "text"
      },
      "source": [
        "**Check if NAs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2sjClIA9QOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_data.isna().any()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjHaZnph9V3A",
        "colab_type": "text"
      },
      "source": [
        "**Remove cases where there are missing values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f85OtiV9yy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_data = gene_data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp6ELmfIHKG6",
        "colab_type": "text"
      },
      "source": [
        "**Check number of patients after removing Nas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGUGuNmKB0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLtwUznBJliI",
        "colab_type": "text"
      },
      "source": [
        "**Create a dataset just containing gene expression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d39noFie28iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove event, os_motnhs, and Five_Year from the dataset\n",
        "genes = gene_data.drop(columns=[\"Unnamed: 0\", \"EVENT\", \"OS_MONTHS\", \"FIVE_YEAR\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zut5zJUr4fAJ"
      },
      "source": [
        "# **Principal Component Analysis**\n",
        "\n",
        "**What is a Pricipal Component? (From DataCamp)**\n",
        "\n",
        "Principal componenets have both direction and magnitude. The direction represents across which principal axes the data is mostly spread out or has the most variance and the magnitude signifies the amount of varaince that Principal Component captures of the data when projected onto that axis. \n",
        "\n",
        "The principal components are a straight line, and the first principal component holds the most variance in the data. Each subsequent prinicpal component is orthogonal to the last and has a lesser variance .\n",
        "\n",
        "Correlated features contribute to the same principal component, thereby reducing the original data features into uncorrelated prinicpal components; each representing a different set of correlated features with differents of variation.\n",
        "\n",
        "Each principal component represents a percentage of total variation captured from the data\n",
        "\n",
        "****Note:** I troubleshooted some discrepancies among the references above in regards to fit and fit transform. Some articles would initially use fit_transform to scale and then again used pca.fit_transform when identifying prinicipal components, other references, instead of fit_transform just used pca.transform for this step. I tested both methods and got the same results. Actually looks like maybe using fit_transform is probably just comnbining these steps?****** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riSqBLBQ0oK7",
        "colab_type": "text"
      },
      "source": [
        "**1) Standardize the Data**\n",
        "\n",
        "Must scale features in your data before applying PCA. **StandardScaler** helps standardize features onto unit scale (mean = 0 and standard deviation = 1). Thus, each value in the dataset will have the sample mean value subtracted and then divided by the standard deviation of the whole dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWr1RzF12Pyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Stanardize/Scale the data\n",
        "x = StandardScaler().fit_transform(genes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsDxV1qR_OzR",
        "colab_type": "text"
      },
      "source": [
        "**Let's check whether the normalized data has a mean of zero and a standard deviation of 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6yRTfin_KEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "af417ba7-7496-4ccb-e3aa-ea1fd1f5815e"
      },
      "source": [
        "np.mean(x), np.std(x)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.1760406566772064e-19, 0.9999999999999999)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxfOsqolHaHZ",
        "colab_type": "text"
      },
      "source": [
        "**Troubleshoot:**\n",
        "\n",
        "I was seeing differences in some of my references regarding whether the pca function should be followed by fit(x) or fit_transform(x) where x is our scaled data. \n",
        "\n",
        "As an update, I tried both methods, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NKekvnmDRw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#11.19.2019 EDIT/TEST - this is like the youtube video https://www.youtube.com/watch?v=Lsue2gEM9D0&list=PLblh5JKOoLUIcdlgu78MnlATeyx4cEVeR&index=54&t=0s \n",
        "pca = PCA()\n",
        "pca.fit(x)\n",
        "test1 = pca.transform(x)\n",
        "test1 = pd.DataFrame(test1)\n",
        "test1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0GfwIWVJwbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test 2 - fit_transform is used twice, does this have any repercussions?\n",
        "# From  https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
        "# Data camp only looks to follow this method - https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python\n",
        "pca = PCA()\n",
        "test2 = pca.fit_transform(x)\n",
        "test2 = pd.DataFrame(test2)\n",
        "test2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XPWKlrOJ9wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine whether the data frames are the same\n",
        "test1.equals(test2) # this indicates that they are not"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNGaoJtpNhex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#why is this false?\n",
        "test3 = pd.concat([test1,test2]).drop_duplicates(keep=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBKCJTFcN3UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test2[ ~test2.isin(test1)].dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27nD10jLOISh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test3 = test1 != test2\n",
        "\n",
        "test3[0].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9I1_-JIN7MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test3.to_csv('/content/drive/My Drive/Projects/Breast_Cancer_Classification/Data/pca_test.csv')\n",
        "test1.to_csv('/content/drive/My Drive/Projects/Breast_Cancer_Classification/Data/pca_test1.csv')\n",
        "test2.to_csv('/content/drive/My Drive/Projects/Breast_Cancer_Classification/Data/pca_test2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCsCz7jNRfgc",
        "colab_type": "text"
      },
      "source": [
        "I manually evaluated the discrepancies by exporting each test and the true/false analysis to excel. \n",
        "\n",
        "From my trouble shooting, it looks like discrepancies are like 10 decimal places in. I'm not sure why this is occcuring, maybe a rounding issue, but I don't think this is a huge problem to stress about right now - because most of the sources seem to be using the fit_transform , I will probably start with that. I can then always validate and see whether the Prinicipal components differ. I don't believe we use this information in the neural network - we would just use the genes "
      ]
    }
  ]
}