{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks_Clinical_Genetic_Analysis",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghutch/Breast-Cancer-Classification-Clinical-Genomic/blob/master/Neural_Networks_Clinical_Genetic_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfhIBpuAWrrO",
        "colab_type": "text"
      },
      "source": [
        "# **Predicting Clinical Outcomes of Breast Cancer Patients**\n",
        "\n",
        "## **Analysis of Clinical Outcomes and Gene Expression**\n",
        "\n",
        "**Author:** Meg Hutch\n",
        "\n",
        "**Date:** December 6, 2019\n",
        "\n",
        "**Objective:** We will examine models using just clinical data and then we will resassess using combined clinical + genomioc data to predict patient surivival greater than 10 years.\n",
        "\n",
        "Unlike the **Neural_Network_Clinical_Outcomes** analysis, this will use the patients in the merged_expression.txt that were processed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xl-wjp_WmUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mamswLh8QkLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect Colab to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sds0C37hUMd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import Data\n",
        "# Clinical Data\n",
        "bc_data = pd.read_csv('/content/drive/My Drive/Projects/Breast_Cancer_Classification/Data/data_clinical_patient.csv')\n",
        "# Gene Expression Data \n",
        "gene_data = pd.read_csv('/content/drive/My Drive/Projects/Breast_Cancer_Classification/Data/merged_expression.txt', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAKBHKzCa4DH",
        "colab_type": "text"
      },
      "source": [
        "# **Pre-Process Data**\n",
        "\n",
        "**Clinical Data**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P42uFeTBlPX0",
        "colab_type": "text"
      },
      "source": [
        "Rows 0-3 contain definitions of data and data types. We can remove these"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_Od_3KdbGQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bc_data = bc_data.iloc[4:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prEZQHwscm0B",
        "colab_type": "text"
      },
      "source": [
        "Convert first row to header name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWaxqLvXbO1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert first row to header name\n",
        "bc_data = bc_data.rename(columns=bc_data.iloc[0]).drop(bc_data.index[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0yvqaoNcy3I",
        "colab_type": "text"
      },
      "source": [
        "Convert column names to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85VrahjfcP3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert column names to lowercase\n",
        "bc_data.columns = map(str.lower, bc_data.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WiKXth4Kmyck"
      },
      "source": [
        "In the project directions, it says we can treat \"Died of Other Causes\" as living. Thus, change the category title as such."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QwM7BYIJmycq",
        "colab": {}
      },
      "source": [
        "bc_data['vital_status'] = bc_data['vital_status'].replace({'Living': 'Living', 'Died of Disease': 'Died of Disease', 'Died of Other Causes': 'Living'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZsZdNjY2lBi",
        "colab_type": "text"
      },
      "source": [
        "Remove any incomplete cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYBjnHVN12dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bc_data = bc_data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC5WoxDe3csQ",
        "colab_type": "text"
      },
      "source": [
        "I'm not sure if sometimes there are missing values just because something wasn't performed, in the case of surgery perhaps? Either way...I'm just going to remove missing values -- May be good to ask about this though"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_NkdoqfjmiUU"
      },
      "source": [
        "**One Hot Encoding**\n",
        "\n",
        "Because some categorical features have multiple categories, we need to use one-hot-encoding to represent these varaibles in the dataset. Just creating numeric levels won't always make sense in the case of features like caludin_subtype which are genomic classifications\n",
        "\n",
        "For features that are binary - we will not need to seperate these into 2 variables - does not make sense!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LI5MqXipmiUZ",
        "colab": {}
      },
      "source": [
        "# Determine which variables we want to one-hot-encode\n",
        "print('Cellularity:', bc_data['cellularity'].unique())\n",
        "print('Chemotherapy:',bc_data['chemotherapy'].unique()) # binary\n",
        "print('Er_ihc:',bc_data['er_ihc'].unique()) # binary \n",
        "print('Her2_snp6:',bc_data['her2_snp6'].unique())\n",
        "print('Hormone Therapy:',bc_data['hormone_therapy'].unique()) # binary\n",
        "print('Inferred_menopausal_state:',bc_data['inferred_menopausal_state'].unique()) # binary\n",
        "print('Interclust:',bc_data['intclust'].unique())\n",
        "print('Claudin_Subtype:',bc_data['claudin_subtype'].unique())\n",
        "print('Threegene:',bc_data['threegene'].unique())\n",
        "print('Laterality:',bc_data['laterality'].unique()) # binary\n",
        "print('Radio_Therapy:',bc_data['radio_therapy'].unique()) # bianry\n",
        "print('Histological_Subtype:',bc_data['histological_subtype'].unique())\n",
        "print('Breast_Surgery:',bc_data['breast_surgery'].unique())\n",
        "print('Vital_status:',bc_data['vital_status'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rG6TBfsFmiUi",
        "colab": {}
      },
      "source": [
        "# Convert patient_ids to row names \n",
        "bc_data = bc_data.set_index(bc_data.patient_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2bjIzr3SmiUn",
        "colab": {}
      },
      "source": [
        "# Create dataframe with the unchanged varaibles - this will contain numeric variables\n",
        "bc_data1 = bc_data[['lymph_nodes_examined_positive', 'npi', 'age_at_diagnosis', 'os_months', 'vital_status', 'chemotherapy', 'er_ihc', 'hormone_therapy', 'inferred_menopausal_state', 'radio_therapy', 'laterality']]\n",
        "\n",
        "## Seperate the dataframes into the variables that we will want to reshape - we can then recombine anything that has more than 2 levels\n",
        "# Cellularity\n",
        "cell_df = bc_data[['cellularity']]\n",
        "cell_df = pd.get_dummies(cell_df,prefix=['cellularity'])\n",
        "\n",
        "# Her2_snp6\n",
        "her2_df = bc_data[['her2_snp6']]\n",
        "her2_df = pd.get_dummies(her2_df,prefix=['her2'])\n",
        "\n",
        "# Interclust\n",
        "intclust_df = bc_data[['intclust']]\n",
        "intclust_df = pd.get_dummies(intclust_df,prefix=['intclust'])\n",
        "\n",
        "# Claduin Subtype\n",
        "cs_df = bc_data[['claudin_subtype']]\n",
        "cs_df = pd.get_dummies(cs_df,prefix=['claudin_subtype'])\n",
        "\n",
        "# Threegene\n",
        "three_df = bc_data[['threegene']]\n",
        "three_df = pd.get_dummies(three_df,prefix=['threegene'])\n",
        "\n",
        "# Histological_Subtype\n",
        "hist_df = bc_data[['histological_subtype']]\n",
        "hist_df = pd.get_dummies(hist_df,prefix=['hist'])\n",
        "\n",
        "# Breast Surgery\n",
        "surg_df = bc_data[['breast_surgery']]\n",
        "surg_df = pd.get_dummies(surg_df,prefix=['breast_surgery'])\n",
        "\n",
        "# We want to convert row index (patient_id) to the first column for all of the above datasets\n",
        "bc_data1.reset_index(level=0, inplace=True)\n",
        "cell_df.reset_index(level=0, inplace=True)\n",
        "her2_df.reset_index(level=0, inplace=True)\n",
        "intclust_df.reset_index(level=0, inplace=True)\n",
        "cs_df.reset_index(level=0, inplace=True)\n",
        "three_df.reset_index(level=0, inplace=True)\n",
        "hist_df.reset_index(level=0, inplace=True)\n",
        "surg_df.reset_index(level=0, inplace=True)\n",
        "\n",
        "# Merge all data \n",
        "bc_data = pd.merge(bc_data1, cell_df, how=\"left\", on=\"patient_id\")\n",
        "bc_data = pd.merge(bc_data, her2_df, how=\"left\", on=\"patient_id\")\n",
        "bc_data = pd.merge(bc_data, intclust_df, how=\"left\", on=\"patient_id\")\n",
        "bc_data = pd.merge(bc_data, cs_df, how=\"left\", on=\"patient_id\")\n",
        "bc_data = pd.merge(bc_data, three_df, how=\"left\", on=\"patient_id\")\n",
        "bc_data = pd.merge(bc_data, hist_df, how=\"left\", on=\"patient_id\")\n",
        "bc_data = pd.merge(bc_data, surg_df, how=\"left\", on=\"patient_id\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ukcahmrDmiUw"
      },
      "source": [
        "Create dummy variables for Vital Status - Our Label and the other binary variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wjXZeKeGmiUx",
        "colab": {}
      },
      "source": [
        "bc_data['vital_status'] = bc_data.vital_status.map({'Living': 0, 'Died of Disease': 1})\n",
        "bc_data['chemotherapy'] = bc_data.chemotherapy.map({'NO': 0, 'YES': 1})\n",
        "bc_data['er_ihc'] = bc_data.er_ihc.map({'Negative': 0, 'Positve': 1}) # careful with the positive spelling error in the dataset\n",
        "bc_data['hormone_therapy'] = bc_data.hormone_therapy.map({'NO': 0, 'YES': 1})\n",
        "bc_data['inferred_menopausal_state'] = bc_data.inferred_menopausal_state.map({'Pre': 0, 'Post': 1})\n",
        "bc_data['laterality'] = bc_data.laterality.map({'Left': 0, 'Right': 1})\n",
        "bc_data['radio_therapy'] = bc_data.radio_therapy.map({'NO': 0, 'YES': 1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yNDj16JSsW56"
      },
      "source": [
        "Covert numeric varaibles as such, right now they are all non-null objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m7wveepYsW5_",
        "colab": {}
      },
      "source": [
        "# convert first column to row index\n",
        "bc_data = bc_data.set_index('patient_id')\n",
        "\n",
        "# convert column object type to float for all columns\n",
        "bc_data = bc_data.astype(np.float32)\n",
        "\n",
        "# convert the row index back to the first column\n",
        "bc_data.reset_index(level=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvEAYV7AdnUy",
        "colab_type": "text"
      },
      "source": [
        "**Gene Expression Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN3qdFp3iAXi",
        "colab_type": "text"
      },
      "source": [
        "Rename patient ID column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2awWt2puh_3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_data.rename(columns={'Unnamed: 0':'patient_id'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhv4Xmt4CEjc",
        "colab_type": "text"
      },
      "source": [
        "Remove redundant columns that also appear in the bc_data - EVENT indicates 5 year survival from the processing code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzzDhbSgCGW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_data = gene_data.drop(columns=[\"EVENT\", \"OS_MONTHS\", \"FIVE_YEAR\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yOA86mVZjw-H"
      },
      "source": [
        "Remove genes if there are missing values.\n",
        "\n",
        "There are so many gene expression variables that I will not exclude patients if they are missing genetic data! Suprisingly, this only removes 6 genes which doesn't seem like it would make a big deal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xHEkcgpAK1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how many genes (columns) are complete cases?\n",
        "gene_data = gene_data.dropna(axis = 1) #axis = 1, represents dropping columns with any missing values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG0jkv53dzjL",
        "colab_type": "text"
      },
      "source": [
        "**Merge Clinical and Gean Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsEkpsAOd7D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clinical_gene = pd.merge(bc_data, gene_data, how=\"left\", on=\"patient_id\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sACE1PvgnEhf"
      },
      "source": [
        "# **Examine Patient Outcomes**\n",
        "\n",
        "Assess the number of patients maintained in our final datasets and their outcomes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cy1Bjfi6nEhk",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "plt_out = clinical_gene.vital_status.value_counts().plot(kind=\"bar\")\n",
        "plt_out.tick_params(axis=\"x\", labelsize=11, labelrotation= -360)\n",
        "plt_out.set_title(\"Survival\")\n",
        "\n",
        "# Calculate Percents\n",
        "count_outcomes = clinical_gene.groupby(['vital_status']).size()\n",
        "print(count_outcomes)\n",
        "\n",
        "print('Total Number of Patients:', len(clinical_gene.index))\n",
        "print('Percent Living: {:.2f}'.format(count_outcomes[0]/len(clinical_gene.index)))\n",
        "print('Percent Died of Disease: {:.2f}'.format(count_outcomes[1]/len(clinical_gene.index)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0LSJM5jlhZR",
        "colab_type": "text"
      },
      "source": [
        "After removing patients with missing clinical values, our dataset reduced to \n",
        "1,519 patients with 49 clinical variables (after one hot encoding) and mRNA expression for 24,368 genes. \n",
        "\n",
        "485 (32% of patients died from breast cancer) vs 1,034 (68%) of patients who surived. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlYTYc7lwvOZ",
        "colab_type": "text"
      },
      "source": [
        "# **Assess the number of patients who surivived > 10 years**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS5ARnT33T_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examine patients who survived > 10 years\n",
        "years10 = clinical_gene[clinical_gene['os_months'] >= 120]\n",
        "os = clinical_gene['os_months']\n",
        "\n",
        "# Define bins\n",
        "bin_edges = [25,50,75,100,125,150,175,200,225,250,275,300,325]\n",
        "\n",
        "plt.hist(os,\n",
        "         bin_edges,\n",
        "         density=False,\n",
        "         histtype='bar',\n",
        "         color='b',\n",
        "         edgecolor='k',\n",
        "         alpha=0.5)\n",
        "\n",
        "plt.xlabel('Months')\n",
        "plt.ylabel('Number Patients')\n",
        "plt.title('Overall Surivival (months)')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc1IuEw35LaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate Percents\n",
        "count_outcomes = years10.groupby(['vital_status']).size()\n",
        "print(count_outcomes)\n",
        "\n",
        "print('Total Number of Patients:', len(years10.index))\n",
        "print('Percent Living: {:.2f}'.format(count_outcomes[0]/len(years10.index)))\n",
        "print('Percent Died of Disease: {:.2f}'.format(count_outcomes[1]/len(years10.index)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RmpBUCk79Jp",
        "colab_type": "text"
      },
      "source": [
        "The number of patients who are still living vs those deceased at 10 years is very unbalanced (87 vs 13% respectively). For this reason, I will continue to see whether my model can just predict survival status for patients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHSb_8vfnj7F",
        "colab_type": "text"
      },
      "source": [
        "# **Prinicipal Component Analysis**\n",
        "\n",
        "**What is a Pricipal Component?**\n",
        "\n",
        "Principal componenets have both direction and magnitude. The direction represents across which principal axes the data is mostly spread out or has the most variance and the magnitude signifies the amount of varaince that Principal Component captures of the data when projected onto that axis. \n",
        "\n",
        "The principal components are a straight line, and the first principal component holds the most variance in the data. Each subsequent prinicpal component is orthogonal to the last and has a lesser variance .\n",
        "\n",
        "Correlated features contribute to the same principal component, thereby reducing the original data features into uncorrelated prinicpal components; each representing a different set of correlated features with differents of variation.\n",
        "\n",
        "Each principal component represents a percentage of total variation captured from the data\n",
        "\n",
        "**Reference:** https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLtwUznBJliI",
        "colab_type": "text"
      },
      "source": [
        "Create a dataset just containing gene expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d39noFie28iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove patient_id number from the list\n",
        "gene_list = gene_data.drop(columns=[\"patient_id\"])\n",
        "gene_list = list(gene_list.columns.values) \n",
        "genes = clinical_gene[gene_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DgHGkhOxDS9",
        "colab_type": "text"
      },
      "source": [
        "Create a dataset containing the target variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUEg7yf_VhS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subset only the Event - whether they lived (0) or died (1) from Breast Cancer\n",
        "labels = clinical_gene.vital_status\n",
        "\n",
        "# Create a list of row names\n",
        "patients = list(clinical_gene.patient_id)\n",
        "\n",
        "# Convert labels into a dataframe and indicate patients as the index\n",
        "labels = pd.DataFrame(labels)\n",
        "labels.index = patients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LcNAgmZwbTgQ"
      },
      "source": [
        "**1) Standardize the Data**\n",
        "\n",
        "Must scale features in your data before applying PCA. **StandardScaler** helps standardize features onto unit scale (mean = 0 and standard deviation = 1). Thus, each value in the dataset will have the sample mean value subtracted and then divided by the standard deviation of the whole dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C8fw-kJMbTgV",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Stanardize/Scale the data\n",
        "x = StandardScaler().fit_transform(genes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RYSjIvVMbTgo"
      },
      "source": [
        "**Let's check whether the normalized data has a mean of zero and a standard deviation of 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xDv7qQHUbTgs",
        "colab": {}
      },
      "source": [
        "np.mean(x), np.std(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2pzskJS_UEz",
        "colab_type": "text"
      },
      "source": [
        "**Convert the normalized features into tabular format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xKkBbp4_W3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create list of column names\n",
        "features = list(genes.columns.values) \n",
        "\n",
        "# Create data frame of newly normalized data - use patients IDs as the index \n",
        "x = pd.DataFrame(x, columns = features, index = patients)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFQt5RulAiYC",
        "colab_type": "text"
      },
      "source": [
        "**2) Determine Prinicpal Components**\n",
        "\n",
        "Reference: https://stackoverflow.com/questions/42167907/understanding-scikitlearn-pca-transform-function-in-python\n",
        "\n",
        "**pca.fit** allows PCA function to compute vectors that you can project your data onto in order to reduce the dimension of your data. \n",
        "\n",
        "**pca.transform** actually performs the projection. It projects each row of data into the vector space that was learned when fit was called.\n",
        "\n",
        "from sklearn: **fit_transform**: Fit the model with X and apply the dimensionality reduction on X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhT8EtKgHCh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define pca function\n",
        "pca = PCA()\n",
        "\n",
        "# Fit to the scaled/standardized data - then use transform to prokect into the new vector space learned by fit\n",
        "principalComponents = pca.fit_transform(x)\n",
        "\n",
        "# Generate a list of column names with the number for each prinicpal component \n",
        "col_names = [f'pc{i}' for i in range(1, 1520)] # there are 1519 samples - so we want to have range of 1 less than 1894 column names \n",
        "\n",
        "# Add column names to the principal component dataset \n",
        "principalDf = pd.DataFrame(principalComponents, columns = col_names, index = patients)\n",
        "principalDf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ERnjKTMe2Nj"
      },
      "source": [
        "**3) Determine # of Components and Variance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anB37-Bse2N8",
        "colab": {}
      },
      "source": [
        "#Plotting the Cumulative Summation of the Explained Variance\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)') #for each component\n",
        "plt.title('Gene Expression Explained Variance')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ntR3kSyfA8w"
      },
      "source": [
        "The plot tells us that with ~1200 components we can capture 90% of the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TW4-aX_0fkCF"
      },
      "source": [
        "**Alternative method - Pre-selecting % of variance**\n",
        "\n",
        "**Fit PCA to the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "08TMwSQzfkCj",
        "colab": {}
      },
      "source": [
        "pca = PCA(0.9)\n",
        "x2 = pca.fit_transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etk-AvMGcPSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x2 = pd.DataFrame(data = x2)\n",
        "x2 #this is the 1306 principal components"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fjoKMBrkfkC6"
      },
      "source": [
        "**Determine the exact number of n_components needed to capture 0.9 variance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O263KB9PfkDA",
        "colab": {}
      },
      "source": [
        "pca.n_components_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N_phdwqSfkDR"
      },
      "source": [
        "This function indicates that 1082 is the number of principal components needed to capture 90% of the variation which is what I had estimated from the above plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-8HMNYOfb-T",
        "colab_type": "text"
      },
      "source": [
        "**Scree Plot**\n",
        "\n",
        "View which principal components contribute most to the variance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Naiy12_fmgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove PC from \n",
        "per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
        "per_var = per_var[:10] #top 10 PC - this number is chosen just so that we can more easily view the plot\n",
        "labels = col_names[:10]\n",
        "\n",
        "plt.bar(x=range(1, len(per_var)+1), height = per_var, tick_label = labels)\n",
        "plt.ylabel('Percentage of Explained Variance')\n",
        "plt.xlabel('Prinicpal Component')\n",
        "plt.title('Scree Plot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRoImRth9d7x",
        "colab_type": "text"
      },
      "source": [
        "**Table with % Variance for the 1082 PCs making up 90% of the variance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CSeS-DT9lqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "per_var_all = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
        "per_var_all.shape # this shows the % variance explained for each component\n",
        "\n",
        "# convert to dataframe\n",
        "per_var_all = pd.DataFrame(per_var_all)\n",
        "\n",
        "# add prinicipal component labels\n",
        "per_var_all.index = col_names[:1082]\n",
        "\n",
        "# rename column 0\n",
        "cols = {'% Variance'}\n",
        "per_var_all.columns = cols\n",
        "\n",
        "# create a rolling calculation of the variance \n",
        "per_var_all['CumulativeVariance'] = per_var_all['% Variance'].cumsum()\n",
        "print(per_var_all)\n",
        "\n",
        "# save to csv \n",
        "per_var_all.to_csv('/content/drive/My Drive/Projects/Breast_Cancer_Classification/Processed_Data/component_variance_chart_90_1082.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbKCKk7EklZW",
        "colab_type": "text"
      },
      "source": [
        "**Draw PCA Plot**\n",
        "\n",
        "With the two primary principal components\n",
        "\n",
        "References: \n",
        "\n",
        "https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python\n",
        "\n",
        "https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju-lFlNjkqrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can use the function below with .sample to select a subset of PC components, making it more readible\n",
        "principalDf_samp = principalDf.sample(n = 500) # will need to change the dataframe principalDf below to prinicpalDf_samp if I use this function\n",
        "\n",
        "#plt.scatter(principalDf.pc1, principalDf.pc2)\n",
        "plt.title('Principal Components')\n",
        "plt.xlabel('PC1 - {0}%'.format(per_var[0]))\n",
        "plt.ylabel('PC2 - {0}%'.format(per_var[1]))\n",
        "\n",
        "# Replace Labels\n",
        "clinical_gene = clinical_gene.set_index(clinical_gene.patient_id)\n",
        "clinical_gene['vital_status'].replace(0, 'Lived',inplace=True)\n",
        "clinical_gene['vital_status'].replace(1, 'Died',inplace=True)\n",
        "\n",
        "# Create labels for the targets to be used to color the graphs\n",
        "targets = ['Lived', 'Died']\n",
        "colors = ['b', 'r']\n",
        "\n",
        "for target, color in zip(targets, colors):\n",
        "    indicesToKeep = clinical_gene['vital_status'] == target\n",
        "    plt.scatter(principalDf.loc[indicesToKeep, 'pc1'],\n",
        "                principalDf.loc[indicesToKeep, 'pc2'], c = color)\n",
        "\n",
        "# The labeled numbers are the indiviudal patients samples\n",
        "for sample in principalDf.index:\n",
        "  plt.annotate(sample, (principalDf.pc1.loc[sample], principalDf.pc2.loc[sample])) # my impression is that sample just indicates each row\n",
        "\n",
        "# Subset\n",
        "#sample_50 = principalDf.sample(n = 50)\n",
        "\n",
        "# This plot is interesting -- it looks like it's creating random samples, but still impossing it on the main graph because we are indeicating pc1 and pc2 still which all samples would be under\n",
        "#for sample in sample_50.index:\n",
        "#  plt.annotate(sample, (sample_50.pc1.loc[sample], sample_50.pc2.loc[sample]))\n",
        "#print(sample_50)\n",
        "\n",
        "#print(principalDf.sample) -- I believe sample is returning just all of the row labels -- hard to read though which is why I was trying to subset\n",
        "#print(principalDf.sample(n = 50))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj1slhOvq7R2",
        "colab_type": "text"
      },
      "source": [
        "**Determine Relevant Genes**\n",
        "\n",
        "Get the name of the top 10 genes that contribute most to pc1. The following code looks at the components of each pca - which is also called the loading scores. Sorting by the absolute value, allows us to identify which genes, in either the negative or positive direction, had the most infleunce on each prinicipal component.\n",
        "\n",
        "\n",
        "\n",
        "References: \n",
        "\n",
        "https://stackoverflow.com/questions/47370795/pca-on-sklearn-how-to-interpret-pca-components\n",
        "\n",
        "https://www.youtube.com/watch?v=FgakZw6K1QQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L2d7XvVqimM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## first, get the loading scores\n",
        "loading_scores = pd.Series(pca.components_[0], index=features)\n",
        "\n",
        "## now sort the loading scores based on their magnitude\n",
        "sorted_loading_scores = loading_scores.abs().sort_values(ascending=False)\n",
        " \n",
        "# get the names of the top 10 genes\n",
        "top_10_genes = sorted_loading_scores[0:10].index.values\n",
        " \n",
        "## print the gene names and their scores (and +/- sign)\n",
        "print(loading_scores[top_10_genes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG7w6zxOYM20",
        "colab_type": "text"
      },
      "source": [
        "**Loading Scores Test**\n",
        "\n",
        "We can also validate the above loading scores function by looking at the values obtained when just using pca.fit. First, we perform just the fit function on the original x which is the scaled/standardized data. Then we can view the compoenent/loading scores which allow us to examine which genes had the most influence for each component. It is the absolute value "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ciVW2jYMaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test\n",
        "principalComponents = pca.fit(x)\n",
        "df_test = pd.DataFrame(pca.components_, columns=list(x.columns))  \n",
        "print(df_test.SEPT15)\n",
        "print(df_test.GLRX3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE1xQmGOpOAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca.components_.shape # when we look at the shape, there are 1306 rows (components) and 24368 columns for the gene features "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD1ZTkuETUzr",
        "colab_type": "text"
      },
      "source": [
        "**Select the Top 1082 Prinicipal Components that Explain 90 % of the Variance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PG856HFThUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "principalDf_1082 = principalDf.iloc[:,0:1082]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKzlNG-xu4EN",
        "colab_type": "text"
      },
      "source": [
        "# **Training and Testing Split**\n",
        "\n",
        "For all of our classification methods, we will create a training and a testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxdYyZxEujxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Packagess\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScK7nf14JEJj",
        "colab_type": "text"
      },
      "source": [
        "Create clinical dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ItAs8Em1Ij_W",
        "colab": {}
      },
      "source": [
        "# Convert patient_ids to row names \n",
        "bc_data = bc_data.set_index(bc_data.patient_id)\n",
        "# remove os_months + vital status from bc_data\n",
        "clinical = bc_data.drop(columns=[\"patient_id\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKwf3jzovYN0",
        "colab_type": "text"
      },
      "source": [
        "Format the bc_data into a features and label dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H421ISlCvf4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let x represent the input features; y the labels\n",
        "# Want to remove os_months, os_status, and vital_status from inputs since these are what we are trying to predict. We will include vital status as our label. I already remove os_status by leaving it out of pre-processing above, since I felt this was similar to vital_status\n",
        "\n",
        "# create x to represent the input features; y is the label; \n",
        "x =  clinical.drop(['os_months', 'vital_status'], axis=1)\n",
        "y =  clinical.vital_status"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jot8CaTpvfEP",
        "colab_type": "text"
      },
      "source": [
        "Split the data into testing and training sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuPWs5pQv5d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7UGiy4twHbY",
        "colab_type": "text"
      },
      "source": [
        "View the shapes of the training and testing sets; the datasets ending in \"train\" are our training sets; similarly, those ending in \"test\" are the testing; x prefix always represents the input features, y the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujubXxyzwU14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assess the trainig and testing sets previously created\n",
        "print('Training Features Shape:', X_train.shape)\n",
        "print('Training Labels Shape:', y_train.shape)\n",
        "print('Testing Features Shape:', X_test.shape)\n",
        "print('Testing Labels Shape:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2u1NBiEwYeS",
        "colab_type": "text"
      },
      "source": [
        "Examine the class distributions - these are similar splits between the training and testing sets. This is also representative of the number of cases throughout the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzAqXr4pwX3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Malignant = 1; Count the number of malignant and determine the percentage (training has 1139 values, testing has 380)\n",
        "print('Died of Diseases in Training Set:', np.count_nonzero(y_train == 1))\n",
        "print('Died of Diseases in Testing Set:', np.count_nonzero(y_test == 1))\n",
        "\n",
        "# Percents\n",
        "print('% Died of Diseases Cases in Training Set:', round(np.count_nonzero(y_train == 1)/1139*100,2))\n",
        "print('% Died of Diseases Cases in Testing Set:', round(np.count_nonzero(y_test == 1)/380*100,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbcbk0qJpqQ",
        "colab_type": "text"
      },
      "source": [
        "Now add the PCs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VBIdNvbuIj_f",
        "colab": {}
      },
      "source": [
        "# Merge pcas with the clinical data\n",
        "pca50 = principalDf_1082.iloc[:,0:50] \n",
        "pca10 = principalDf_1082.iloc[:,0:10]\n",
        "\n",
        "# name row index\n",
        "pca50.index.name = 'patient_id'\n",
        "pca10.index.name = 'patient_id'\n",
        "\n",
        "# convert the row index back to the first column\n",
        "pca50.reset_index(level=0, inplace=True)\n",
        "pca10.reset_index(level=0, inplace=True)\n",
        "\n",
        "# Merge pca with clinical data\n",
        "X_train_clinical_pca50 = pd.merge(X_train, pca50, how=\"left\", on=\"patient_id\")\n",
        "X_test_clinical_pca50 = pd.merge(X_test, pca50, how=\"left\", on=\"patient_id\")\n",
        "\n",
        "X_train_clinical_pca10 = pd.merge(X_train, pca10, how=\"left\", on=\"patient_id\")\n",
        "X_test_clinical_pca10 = pd.merge(X_test, pca10, how=\"left\", on=\"patient_id\")\n",
        "\n",
        "# convert column with patients ids back to row index\n",
        "X_train_clinical_pca50 = X_train_clinical_pca50.set_index(X_train_clinical_pca50.patient_id)\n",
        "X_test_clinical_pca50 = X_test_clinical_pca50.set_index(X_test_clinical_pca50.patient_id)\n",
        "\n",
        "X_train_clinical_pca10 = X_train_clinical_pca10.set_index(X_train_clinical_pca10.patient_id)\n",
        "X_test_clinical_pca10 = X_test_clinical_pca10.set_index(X_test_clinical_pca10.patient_id)\n",
        "\n",
        "# remove patient id column\n",
        "X_train_clinical_pca50 = X_train_clinical_pca50.drop(columns=[\"patient_id\"])\n",
        "X_test_clinical_pca50 = X_test_clinical_pca50.drop(columns=[\"patient_id\"])\n",
        "\n",
        "X_train_clinical_pca10 = X_train_clinical_pca10.drop(columns=[\"patient_id\"])\n",
        "X_test_clinical_pca10 = X_test_clinical_pca10.drop(columns=[\"patient_id\"])\n",
        "\n",
        "# PCAs without clinical data \n",
        "# convert the row index back to the first column\n",
        "X_train.reset_index(level=0, inplace=True)\n",
        "X_test.reset_index(level=0, inplace=True) \n",
        "\n",
        "# Create a patient list of ids for those in the training and test sets - we will use this seperate a pca only dataset\n",
        "X_train_patients = X_train.patient_id\n",
        "X_test_patients = X_test.patient_id\n",
        "\n",
        "# Merge with the pca data\n",
        "X_train_pca50 = pd.merge(X_train_patients, pca50, how=\"left\", on=\"patient_id\")\n",
        "X_test_pca50 = pd.merge(X_test_patients, pca50, how=\"left\", on=\"patient_id\")\n",
        "\n",
        "X_train_pca10 = pd.merge(X_train_patients, pca10, how=\"left\", on=\"patient_id\")\n",
        "X_test_pca10 = pd.merge(X_test_patients, pca10, how=\"left\", on=\"patient_id\")\n",
        "\n",
        "# Convert patients IDs back to row index\n",
        "X_train_pca50 = X_train_pca50.set_index(X_train_pca50.patient_id)\n",
        "X_test_pca50 = X_test_pca50.set_index(X_test_pca50.patient_id)\n",
        "\n",
        "X_train_pca10 = X_train_pca10.set_index(X_train_pca10.patient_id)\n",
        "X_test_pca10 = X_test_pca10.set_index(X_test_pca10.patient_id)\n",
        "\n",
        "# remove patient id column\n",
        "X_train_pca50 = X_train_pca50.drop(columns=[\"patient_id\"])\n",
        "X_test_pca50 = X_test_pca50.drop(columns=[\"patient_id\"])\n",
        "\n",
        "X_train_pca10 = X_train_pca10.drop(columns=[\"patient_id\"])\n",
        "X_test_pca10 = X_test_pca10.drop(columns=[\"patient_id\"])\n",
        "\n",
        "X_train = X_train.drop(columns=[\"patient_id\"])\n",
        "X_test = X_test.drop(columns=[\"patient_id\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaHX5zydw3H2",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic Regression**\n",
        "\n",
        "These steps were followed from the following tutorial:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vwpu6ScZURRm"
      },
      "source": [
        "**50 Principal Components**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iS1LifQFURRt"
      },
      "source": [
        "**Define and Run the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n18Pk7f1URRv",
        "colab": {}
      },
      "source": [
        "# Instantiate the model (using default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train_pca50, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test_pca50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n1z7lC-WURR3"
      },
      "source": [
        "**Model Evaluation Using Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dtbEnm69URR7",
        "colab": {}
      },
      "source": [
        "# import the metrics class\n",
        "from sklearn import metrics\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uFQoe_WKURSA"
      },
      "source": [
        "The confusion matrix generated above is in the form of an array. Diagnosal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. The diagonal starting with the top left to the bottom right hand corner are actual predidictions, while the bottom left corner to the top right corner are incorrect predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iA9ImG6dURSB",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred),3))\n",
        "print(\"Recall:\",round(metrics.recall_score(y_test, y_pred),3))\n",
        "print(\"Precision:\",round(metrics.precision_score(y_test, y_pred),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zpQgUH1UURSG"
      },
      "source": [
        "**ROC**\n",
        "\n",
        "The Reciever Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixaqHxbeURSG",
        "colab": {}
      },
      "source": [
        "y_pred_proba = logreg.predict_proba(X_test_pca50)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label = \"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "print('AUC:', round(auc,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dqn3HPuWUyaE"
      },
      "source": [
        "**10 Principal Components**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oKMJ0SGAUyaO"
      },
      "source": [
        "**Define and Run the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rZrAhT47UyaP",
        "colab": {}
      },
      "source": [
        "# Instantiate the model (using default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train_pca10, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test_pca10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wv9xqbq0UyaU"
      },
      "source": [
        "**Model Evaluation Using Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tgBI5aS5UyaV",
        "colab": {}
      },
      "source": [
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "caO5G3BBUyaX"
      },
      "source": [
        "The confusion matrix generated above is in the form of an array. Diagnosal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. The diagonal starting with the top left to the bottom right hand corner are actual predidictions, while the bottom left corner to the top right corner are incorrect predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Esb1P76uUyaY",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred),3))\n",
        "print(\"Recall:\",round(metrics.recall_score(y_test, y_pred),3))\n",
        "print(\"Precision:\",round(metrics.precision_score(y_test, y_pred),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kv8TqEL1Uyaa"
      },
      "source": [
        "**ROC**\n",
        "\n",
        "The Reciever Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zX1J6K9aUyab",
        "colab": {}
      },
      "source": [
        "y_pred_proba = logreg.predict_proba(X_test_pca10)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label = \"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "print('AUC:', round(auc,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R45RrYnfyDva",
        "colab_type": "text"
      },
      "source": [
        "**Clinical Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BdqKQJ2x0em",
        "colab_type": "text"
      },
      "source": [
        "**Define and Run the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u4X6MFSxzox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the model (using default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRDRV7DIyGL5",
        "colab_type": "text"
      },
      "source": [
        "**Model Evaluation Using Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyJQT7fHyLeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CRpg41RySQT",
        "colab_type": "text"
      },
      "source": [
        "The confusion matrix generated above is in the form of an array. Diagnosal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. The diagonal starting with the top left to the bottom right hand corner are actual predidictions, while the bottom left corner to the top right corner are incorrect predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2BvUFrAy04x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred),3))\n",
        "print(\"Recall:\",round(metrics.recall_score(y_test, y_pred),3))\n",
        "print(\"Precision:\",round(metrics.precision_score(y_test, y_pred),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAZw8J4mzxsD",
        "colab_type": "text"
      },
      "source": [
        "**ROC**\n",
        "\n",
        "The Reciever Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y11_Tmpu39qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label = \"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "print('AUC:', round(auc,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7FHRMqAOBoKq"
      },
      "source": [
        "**Clinical Data + 50 Prinicipal Components**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "99N0pjO2BoK2"
      },
      "source": [
        "**Define and Run the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s4Op2CqIBoK4",
        "colab": {}
      },
      "source": [
        "# Instantiate the model (using default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train_clinical_pca50, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test_clinical_pca50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7VpYDQoDBoK-"
      },
      "source": [
        "**Model Evaluation Using Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lvRw6d0IBoK_",
        "colab": {}
      },
      "source": [
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FGbkL07YBoLG"
      },
      "source": [
        "The confusion matrix generated above is in the form of an array. Diagnosal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. The diagonal starting with the top left to the bottom right hand corner are actual predidictions, while the bottom left corner to the top right corner are incorrect predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m75-9of-BoLH",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred),3))\n",
        "print(\"Recall:\",round(metrics.recall_score(y_test, y_pred),3))\n",
        "print(\"Precision:\",round(metrics.precision_score(y_test, y_pred),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y7qzPCaQBoLM"
      },
      "source": [
        "**ROC**\n",
        "\n",
        "The Reciever Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rljn3PnYBoLN",
        "colab": {}
      },
      "source": [
        "y_pred_proba = logreg.predict_proba(X_test_clinical_pca50)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label = \"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "print('AUC:', round(auc,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9nkSOzxvRQXx"
      },
      "source": [
        "**Clinical Data + 10 Prinicipal Components**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yp3stwjLB6CG"
      },
      "source": [
        "**Define and Run the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R9ZTshzgB6CJ",
        "colab": {}
      },
      "source": [
        "# Instantiate the model (using default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train_clinical_pca10, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test_clinical_pca10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p53M0K2tB6CO"
      },
      "source": [
        "**Model Evaluation Using Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8FZz2WjwB6CP",
        "colab": {}
      },
      "source": [
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pu1cUoCcB6CT"
      },
      "source": [
        "The confusion matrix generated above is in the form of an array. Diagnosal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. The diagonal starting with the top left to the bottom right hand corner are actual predidictions, while the bottom left corner to the top right corner are incorrect predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0bjPNzPsB6CT",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred),3))\n",
        "print(\"Recall:\",round(metrics.recall_score(y_test, y_pred),3))\n",
        "print(\"Precision:\",round(metrics.precision_score(y_test, y_pred),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TKMyJSqbB6CW"
      },
      "source": [
        "**ROC**\n",
        "\n",
        "The Reciever Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XYLmXsKWB6CX",
        "colab": {}
      },
      "source": [
        "y_pred_proba = logreg.predict_proba(X_test_clinical_pca10)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label = \"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "print('AUC:', round(auc,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SoRPmkt6CJ4t",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred),3))\n",
        "print(\"Recall:\",round(metrics.recall_score(y_test, y_pred),3))\n",
        "print(\"Precision:\",round(metrics.precision_score(y_test, y_pred),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M5jCMHP8COG",
        "colab_type": "text"
      },
      "source": [
        "# **Random Forest Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a0putDWXD7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the metrics class sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel # to identify features\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a-cJ4EcNY9w7"
      },
      "source": [
        "**10 Principal Components**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AH09ysGdY9xB"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gjzyrAfOY9xE",
        "colab": {}
      },
      "source": [
        "# Instantiate model with 1000 decision trees - results below reported w/ random state = 42\n",
        "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(X_train_pca10, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rn7OtBKIY9xK"
      },
      "source": [
        "**Select Important Features**\n",
        "\n",
        "Identify which Principal Components contributed most to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zP2C8umXY9xL",
        "colab": {}
      },
      "source": [
        "# First feature selection test\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(X_train_pca10, y_train)\n",
        "sel.get_support()\n",
        "selected_feat= X_train_pca10.columns[(sel.get_support())]\n",
        "print(len(selected_feat)) \n",
        "print(selected_feat)\n",
        "\n",
        "## histogram of the top 10 pc by importance\n",
        "# create a list of features/column names\n",
        "features = list(X_train_pca10.columns.values) \n",
        "\n",
        "feat_importances = pd.Series(rf.feature_importances_, index=X_train_pca10.columns)  \n",
        "feat_importances.nlargest(10).plot(kind='barh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CNeSFBtoY9xN"
      },
      "source": [
        "**Make Predictions on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fH6YI7VcY9xO",
        "colab": {}
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_test_pca10)\n",
        "# Probabilities for each class\n",
        "rf_probs = rf.predict_proba(X_test_pca10)[:, 1]\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - y_test)\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5KVPqZ9eY9xS"
      },
      "source": [
        "**Evaluating the Performance**\n",
        "\n",
        "For Classification Problems the metrics used to evaluate an algorithm are accuracy, confusion matrix, precision, recall, and F1 values.\n",
        "\n",
        "We can also perform cross-fold validation to have a better understanding of the results\n",
        "\n",
        "Reference: https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F5revkhoY9xT"
      },
      "source": [
        "**ROC on the Full Data**\n",
        "\n",
        "\n",
        "We make class predictions (predict) as well as predicted probabilities (predict_proba) to calculate the ROC AUC. Once we have the testing predictions, we can calculate the ROC AUC. https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WMEPOGfpY9xT",
        "colab": {}
      },
      "source": [
        "# Calculate ROC AUC\n",
        "roc_value = roc_auc_score(y_test, rf_probs) \n",
        "roc_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yDOqgxcZY9xW",
        "colab": {}
      },
      "source": [
        "# Probabilities for each class\n",
        "# Note from scikit learn: re fpr and tpr: \"Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both fpr and tpr, which are sorted in reversed order during their calculation.\"\n",
        "rf_probs = rf.predict_proba(X_test_pca10)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, rf_probs)\n",
        "auc = metrics.roc_auc_score(y_test, rf_probs)\n",
        "auc = round(auc, 4)\n",
        "plt.plot(fpr, tpr, label=\"date 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OL5zl1YKY9xY"
      },
      "source": [
        "Below, we also can examine the confusion matrix, the classification report containing precision, recall, f1-score, and support, All AUC scores, and the mean AUC score\n",
        "\n",
        "The **confusion matrix** is useful for giving false positives and false negatives\n",
        "\n",
        "The **ROC Curve** plots out the true positive rate vs the false positive rate at various thresholds\n",
        "\n",
        "The **ROC AUC Scoring** used in the cross-validation model shows the area under the ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dcMjeh_OY9xZ",
        "colab": {}
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Accuracy Score ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RtJhCWGVEu5",
        "colab_type": "text"
      },
      "source": [
        "**50 Principal Components**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpN91JbL9JOA",
        "colab_type": "text"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dsBsgBv9LWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate model with 1000 decision trees - results below reported w/ random state = 42\n",
        "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(X_train_pca50, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZbwAmNQ-XdF",
        "colab_type": "text"
      },
      "source": [
        "**Select Important Features**\n",
        "\n",
        "Identify which Principal Components contributed most to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_MdbNeW-bHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First feature selection test\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(X_train_pca50, y_train)\n",
        "sel.get_support()\n",
        "selected_feat= X_train_pca50.columns[(sel.get_support())]\n",
        "print(len(selected_feat)) \n",
        "print(selected_feat)\n",
        "\n",
        "## histogram of the top 10 pc by importance\n",
        "# create a list of features/column names\n",
        "features = list(X_train_pca50.columns.values) \n",
        "\n",
        "feat_importances = pd.Series(rf.feature_importances_, index=X_train_pca50.columns)  \n",
        "feat_importances.nlargest(10).plot(kind='barh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FENSsY5l9aDT",
        "colab_type": "text"
      },
      "source": [
        "**Make Predictions on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yKF_xdj9dbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_test_pca50)\n",
        "# Probabilities for each class\n",
        "rf_probs = rf.predict_proba(X_test_pca50)[:, 1]\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - y_test)\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5pOirYXDrEn",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating the Performance**\n",
        "\n",
        "For Classification Problems the metrics used to evaluate an algorithm are accuracy, confusion matrix, precision, recall, and F1 values.\n",
        "\n",
        "We can also perform cross-fold validation to have a better understanding of the results\n",
        "\n",
        "Reference: https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu4eohUxFVaA",
        "colab_type": "text"
      },
      "source": [
        "**ROC on the Full Data**\n",
        "\n",
        "\n",
        "We make class predictions (predict) as well as predicted probabilities (predict_proba) to calculate the ROC AUC. Once we have the testing predictions, we can calculate the ROC AUC. https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrO0-IuE-o0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate ROC AUC\n",
        "roc_value = roc_auc_score(y_test, rf_probs) \n",
        "roc_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyKejE-yF88f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Probabilities for each class\n",
        "# Note from scikit learn: re fpr and tpr: \"Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both fpr and tpr, which are sorted in reversed order during their calculation.\"\n",
        "rf_probs = rf.predict_proba(X_test_pca50)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, rf_probs)\n",
        "auc = metrics.roc_auc_score(y_test, rf_probs)\n",
        "auc = round(auc, 4)\n",
        "plt.plot(fpr, tpr, label=\"date 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEonYh2WEhkU",
        "colab_type": "text"
      },
      "source": [
        "Below, we also can examine the confusion matrix, the classification report containing precision, recall, f1-score, and support, All AUC scores, and the mean AUC score\n",
        "\n",
        "The **confusion matrix** is useful for giving false positives and false negatives\n",
        "\n",
        "The **ROC Curve** plots out the true positive rate vs the false positive rate at various thresholds\n",
        "\n",
        "The **ROC AUC Scoring** used in the cross-validation model shows the area under the ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haZRHJqGcv9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Accuracy Score ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8LCddO7caqFc"
      },
      "source": [
        "**Clinical Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yVI9ZK6NaqFl"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BgLlCNGZaqFn",
        "colab": {}
      },
      "source": [
        "# Instantiate model with 1000 decision trees - results below reported w/ random state = 42\n",
        "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ClPP7e7naqFv"
      },
      "source": [
        "**Select Important Features**\n",
        "\n",
        "Identify which Principal Components contributed most to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rkIwQmVnaqFx",
        "colab": {}
      },
      "source": [
        "# First feature selection test\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(X_train, y_train)\n",
        "sel.get_support()\n",
        "selected_feat= X_train.columns[(sel.get_support())]\n",
        "print(len(selected_feat)) \n",
        "print(selected_feat)\n",
        "\n",
        "## histogram of the top 10 pc by importance\n",
        "# create a list of features/column names\n",
        "features = list(X_train.columns.values) \n",
        "\n",
        "feat_importances = pd.Series(rf.feature_importances_, index=X_train.columns)  \n",
        "feat_importances.nlargest(10).plot(kind='barh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kHqz7z0caqF2"
      },
      "source": [
        "**Make Predictions on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pyAAjtX7aqF3",
        "colab": {}
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_test)\n",
        "# Probabilities for each class\n",
        "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - y_test)\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CtC0sUPJaqF7"
      },
      "source": [
        "**Evaluating the Performance**\n",
        "\n",
        "For Classification Problems the metrics used to evaluate an algorithm are accuracy, confusion matrix, precision, recall, and F1 values.\n",
        "\n",
        "We can also perform cross-fold validation to have a better understanding of the results\n",
        "\n",
        "Reference: https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1TwhkBiOaqF8"
      },
      "source": [
        "**ROC on the Full Data**\n",
        "\n",
        "\n",
        "We make class predictions (predict) as well as predicted probabilities (predict_proba) to calculate the ROC AUC. Once we have the testing predictions, we can calculate the ROC AUC. https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rh9MeufqaqF8",
        "colab": {}
      },
      "source": [
        "# Calculate ROC AUC\n",
        "roc_value = roc_auc_score(y_test, rf_probs) \n",
        "roc_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hkciwi2yaqF_",
        "colab": {}
      },
      "source": [
        "# Probabilities for each class\n",
        "# Note from scikit learn: re fpr and tpr: \"Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both fpr and tpr, which are sorted in reversed order during their calculation.\"\n",
        "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, rf_probs)\n",
        "auc = metrics.roc_auc_score(y_test, rf_probs)\n",
        "auc = round(auc, 4)\n",
        "plt.plot(fpr, tpr, label=\"date 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ayl1Ze1aqGB"
      },
      "source": [
        "Below, we also can examine the confusion matrix, the classification report containing precision, recall, f1-score, and support, All AUC scores, and the mean AUC score\n",
        "\n",
        "The **confusion matrix** is useful for giving false positives and false negatives\n",
        "\n",
        "The **ROC Curve** plots out the true positive rate vs the false positive rate at various thresholds\n",
        "\n",
        "The **ROC AUC Scoring** used in the cross-validation model shows the area under the ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ik8Kyd3daqGC",
        "colab": {}
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Accuracy Score ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bgZI55STbdcu"
      },
      "source": [
        "**Clinical Data + 10 Prinicipal Components**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A7uem5Hbbdcy"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kpHVP1_kbdc0",
        "colab": {}
      },
      "source": [
        "# Instantiate model with 1000 decision trees - results below reported w/ random state = 42\n",
        "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(X_train_clinical_pca10, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iUXEKeUpbdc7"
      },
      "source": [
        "**Select Important Features**\n",
        "\n",
        "Identify which Principal Components contributed most to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bkvXPuTgbdc-",
        "colab": {}
      },
      "source": [
        "# First feature selection test\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(X_train_clinical_pca10, y_train)\n",
        "sel.get_support()\n",
        "selected_feat= X_train_clinical_pca10.columns[(sel.get_support())]\n",
        "print(len(selected_feat)) \n",
        "print(selected_feat)\n",
        "\n",
        "## histogram of the top 10 pc by importance\n",
        "# create a list of features/column names\n",
        "features = list(X_train_clinical_pca10.columns.values) \n",
        "\n",
        "feat_importances = pd.Series(rf.feature_importances_, index=X_train_clinical_pca10.columns)  \n",
        "feat_importances.nlargest(10).plot(kind='barh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Ug_NHtabddE"
      },
      "source": [
        "**Make Predictions on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PwZvRUPWbddG",
        "colab": {}
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_test_clinical_pca10)\n",
        "# Probabilities for each class\n",
        "rf_probs = rf.predict_proba(X_test_clinical_pca10)[:, 1]\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - y_test)\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lbkaVv6qbddM"
      },
      "source": [
        "**Evaluating the Performance**\n",
        "\n",
        "For Classification Problems the metrics used to evaluate an algorithm are accuracy, confusion matrix, precision, recall, and F1 values.\n",
        "\n",
        "We can also perform cross-fold validation to have a better understanding of the results\n",
        "\n",
        "Reference: https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Joi87sOVbddN"
      },
      "source": [
        "**ROC on the Full Data**\n",
        "\n",
        "\n",
        "We make class predictions (predict) as well as predicted probabilities (predict_proba) to calculate the ROC AUC. Once we have the testing predictions, we can calculate the ROC AUC. https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0wfMZRnbddO",
        "colab": {}
      },
      "source": [
        "# Calculate ROC AUC\n",
        "roc_value = roc_auc_score(y_test, rf_probs) \n",
        "roc_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cOWGcrexbddQ",
        "colab": {}
      },
      "source": [
        "# Probabilities for each class\n",
        "# Note from scikit learn: re fpr and tpr: \"Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both fpr and tpr, which are sorted in reversed order during their calculation.\"\n",
        "rf_probs = rf.predict_proba(X_test_clinical_pca10)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, rf_probs)\n",
        "auc = metrics.roc_auc_score(y_test, rf_probs)\n",
        "auc = round(auc, 4)\n",
        "plt.plot(fpr, tpr, label=\"date 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ydzXcVunbddT"
      },
      "source": [
        "Below, we also can examine the confusion matrix, the classification report containing precision, recall, f1-score, and support, All AUC scores, and the mean AUC score\n",
        "\n",
        "The **confusion matrix** is useful for giving false positives and false negatives\n",
        "\n",
        "The **ROC Curve** plots out the true positive rate vs the false positive rate at various thresholds\n",
        "\n",
        "The **ROC AUC Scoring** used in the cross-validation model shows the area under the ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wFnCQnlRbddT",
        "colab": {}
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Accuracy Score ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HFHJ3zurct29"
      },
      "source": [
        "**Clinical Data + 50 Prinicipal Components**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UF3jYgypct3A"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sm67V_dCct3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "3a7535d3-c33f-4369-fc3c-f80f5c4ebaa2"
      },
      "source": [
        "# Instantiate model with 1000 decision trees - results below reported w/ random state = 42\n",
        "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(X_train_clinical_pca50, y_train)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2j6QJzrjct3J"
      },
      "source": [
        "**Select Important Features**\n",
        "\n",
        "Identify which Principal Components contributed most to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AVvDcd6Oct3M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "b4d3d547-7bfb-46f0-b21a-fc5bc08ec4be"
      },
      "source": [
        "# First feature selection test\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(X_train_clinical_pca50, y_train)\n",
        "sel.get_support()\n",
        "selected_feat= X_train_clinical_pca50.columns[(sel.get_support())]\n",
        "print(len(selected_feat)) \n",
        "print(selected_feat)\n",
        "\n",
        "## histogram of the top 10 pc by importance\n",
        "# create a list of features/column names\n",
        "features = list(X_train_clinical_pca50.columns.values) \n",
        "\n",
        "feat_importances = pd.Series(rf.feature_importances_, index=X_train_clinical_pca50.columns)  \n",
        "feat_importances.nlargest(10).plot(kind='barh')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n",
            "Index(['lymph_nodes_examined_positive', 'npi', 'age_at_diagnosis', 'pc1',\n",
            "       'pc2', 'pc3', 'pc4', 'pc5', 'pc6', 'pc7', 'pc8', 'pc9', 'pc10', 'pc11',\n",
            "       'pc12', 'pc13', 'pc14', 'pc15', 'pc16', 'pc17', 'pc18', 'pc19', 'pc20',\n",
            "       'pc21', 'pc22', 'pc23', 'pc24', 'pc25', 'pc26', 'pc27', 'pc28', 'pc29',\n",
            "       'pc30', 'pc31', 'pc32', 'pc33', 'pc34', 'pc35', 'pc36', 'pc37', 'pc38',\n",
            "       'pc39', 'pc40', 'pc41', 'pc42', 'pc43', 'pc44', 'pc45', 'pc46', 'pc47',\n",
            "       'pc48', 'pc49', 'pc50'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f88ee6d5588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAD4CAYAAACJ8R5TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nviSWKRUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GzY5dmhUct3U"
      },
      "source": [
        "**Make Predictions on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jjCoRemuct3W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4888ec9a-df7f-4040-b96e-c1c131adeb70"
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_test_clinical_pca50)\n",
        "# Probabilities for each class\n",
        "rf_probs = rf.predict_proba(X_test_clinical_pca50)[:, 1]\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - y_test)\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kzM629v5ct3a"
      },
      "source": [
        "**Evaluating the Performance**\n",
        "\n",
        "For Classification Problems the metrics used to evaluate an algorithm are accuracy, confusion matrix, precision, recall, and F1 values.\n",
        "\n",
        "We can also perform cross-fold validation to have a better understanding of the results\n",
        "\n",
        "Reference: https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7a7as0I1ct3b"
      },
      "source": [
        "**ROC on the Full Data**\n",
        "\n",
        "\n",
        "We make class predictions (predict) as well as predicted probabilities (predict_proba) to calculate the ROC AUC. Once we have the testing predictions, we can calculate the ROC AUC. https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "95BDhr5Dct3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e4ccc55-12aa-408e-9625-643407a78e68"
      },
      "source": [
        "# Calculate ROC AUC\n",
        "roc_value = roc_auc_score(y_test, rf_probs) \n",
        "roc_value"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6782049573560769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5vvJI_lct3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "adfe1601-41c8-4c48-ef71-854604c6d0a4"
      },
      "source": [
        "# Probabilities for each class\n",
        "# Note from scikit learn: re fpr and tpr: \"Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both fpr and tpr, which are sorted in reversed order during their calculation.\"\n",
        "rf_probs = rf.predict_proba(X_test_clinical_pca50)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, rf_probs)\n",
        "auc = metrics.roc_auc_score(y_test, rf_probs)\n",
        "auc = round(auc, 4)\n",
        "plt.plot(fpr, tpr, label=\"date 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEQIFbqISIRQoYuIRAgVuohIhPg/vjx0EfqdVRIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1CqmSJzct3j"
      },
      "source": [
        "Below, we also can examine the confusion matrix, the classification report containing precision, recall, f1-score, and support, All AUC scores, and the mean AUC score\n",
        "\n",
        "The **confusion matrix** is useful for giving false positives and false negatives\n",
        "\n",
        "The **ROC Curve** plots out the true positive rate vs the false positive rate at various thresholds\n",
        "\n",
        "The **ROC AUC Scoring** used in the cross-validation model shows the area under the ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KFvlBPrBct3k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "22e2e3b6-7d06-4ab2-cb18-d7cbf991485f"
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Accuracy Score ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[251  17]\n",
            " [ 83  29]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.94      0.83       268\n",
            "         1.0       0.63      0.26      0.37       112\n",
            "\n",
            "    accuracy                           0.74       380\n",
            "   macro avg       0.69      0.60      0.60       380\n",
            "weighted avg       0.72      0.74      0.70       380\n",
            "\n",
            "\n",
            "\n",
            "=== Accuracy Score ===\n",
            "Accuracy: 0.7368421052631579\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}